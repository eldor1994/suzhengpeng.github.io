<!DOCTYPE html>
<html>

<head>
	<!-- Meta -->
	<meta charset="UTF-8"/>
	<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
	<meta name="generator" content="Jekyll">

	<title>
        
            Hello Pytorch 壹 -- 卷积层原理及实现 - Su'S Blog - SuZhengpeng.COM 
        </title>
  <meta name="description" content="Pytorch 框架的卷积层模块代码阅读笔记 ">

	<!-- CSS & fonts -->
	<link rel="stylesheet" href="/css/main.css">

	<!-- RSS -->
	<link href="/atom.xml" type="application/atom+xml" rel="alternate" title="ATOM Feed" />

  <!-- Favicon -->
  <link rel="shortcut icon" type="image/png" href="/img/favicon.png">
    <style type="text/css">

</style>
<!-- MathJax -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [['$', '$'],['\\(', '\\)']],
            displayMath: [['$$', '$$'],["\\[", "\\]"]],
			skipTags: ['script', 'noscript', 'style', 'textarea', 'pre','code','a'],
            processEscapes: true
        },
        TeX: {
            extensions: ["AMSmath.js", "AMSsymbols.js"],
            equationNumbers: { autoNumber: ["AMS"],
			useLabelIds: true
            },
            Macros: {hfill: "{}"}
        },
        "HTML-CSS": {
            linebreaks: {automatic: true},
            availableFonts: ["TeX"],
            scale: 110
        },
        SVG: {
            linebreaks: {automatic: true}
        }
    });
</script>
<script type="text/javascript"
   src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
//    src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

<!-- Highlight -->

<link rel="stylesheet" href="/styles/atelier-estuary-dark.css">
<script src="/js/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script>

<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>  

<script type="text/javascript" src="/js/jquery-1.8.3.min_2.js"></script>
<!-- <link href='http://fonts.googleapis.com/css?family=Tauri' rel='styl esheet' type='text/css'> -->
<style type="text/css">
	.shang_con{width:100px;margin:20px auto;}
	.shang_hide_box{z-index:999;filter:alpha(opacity=50);background:#666;opacity: 0.5;-moz-opacity: 0.5;left:0;top:0;height:99%;width:100%;position:fixed;display:none;}
	.shang_box{width:540px;height:540px;padding:10px;background-color:#fff;border-radius:10px;position:fixed;z-index:1000;left:50%;top:50%;margin-left:-280px;margin-top:-280px;border:1px dotted #dedede;display:none;}
	.shang_box img{border:none;border-width:0;}
	.dashang{display:block;width:100px;margin:5px auto;height:45px;line-height:25px;padding:10px;background-color:#E74851;color:#fff;text-align:center;text-decoration:none;border-radius:10px;font-weight:bold;font-size:16px;transition: all 0.3s;}
	.dashang:hover{opacity:0.8;padding:15px;font-size:18px;}
	.shang_close{display:inline-block;}
	.shang_logo{display:block;text-align:center;margin:20px auto;}
	.shang_tit{width: 100%;height: 75px;text-align: center;line-height: 66px;color: #a3a3a3;font-size: 16px;font-family: 'Microsoft YaHei';margin-top: 7px;margin-right:2px;}
	.shang_tit p{color:#a3a3a3;text-align:center;font-size:16px;}
	.shang_payimg{width:140px;margin:0 auto;border-radius:3px;height:140px;}
	.shang_payimg img{display:block;text-align:center;width:140px;height:140px; }
	.pay_explain{text-align:center;margin:10px auto;font-size:12px;color:#545454;}
	.radiobox{width: 16px;height: 16px;background: url('img/ds/radio2.jpg');display: block;float: left;margin-right: 14px; margin-left: 50px;margin-bottom: 10px;}
	.checked .radiobox{background:url('img/ds/radio1.jpg');}
	.shang_payselect{text-align:center;margin:0 auto;margin-top:40px;cursor:pointer;height:60px;width:280px;}
	.shang_payselect .pay_item{display:inline-block;margin-right:10px;}
	.shang_info{clear:both;}
	.shang_info p,.shang_info a{color:#C3C3C3;text-align:center;text-decoration:none;line-height:2em;}
</style>
		</head>


<body>
	<div id="wrap">
	  	
	  	<!-- Navigation -->
	  	

<nav id="nav">

    <!-- Nav links -->
	  

  
  <!-- Nav footer 
	
	  <footer><span>

<div class="footer" id="nav-links">

	<div class="footer-one">
	
		<div class="footer-ico"></div>
		<br>
		Suzhengpeng.COM
		<br>
			 <div class="footer-power">
		Proudly hosted by Github and powered by Jekyll <br> All designed by Suzhengpeng.COM </div>
		<br>
	
	</div>
	
	<div class="footer-two">
	
		

	    
		
			<a href="/pages/page/about" title="关于博主">关于博主</a>&nbsp;&nbsp;<br>
		

	    
		

	    
		
			<a href="/pages/page/contact" title="联系方式">联系方式</a>&nbsp;&nbsp;<br>
		

	    
		
			<a href="/pages/page/copyright" title="版权声明">版权声明</a>&nbsp;&nbsp;<br>
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		<br>

	</div>
	<div class="footer-two">
					
				
				
				
				
				
				
				
				
				
				
				
				
				
			<a href="/pages/data/link" title="常用链接">常用链接</a>&nbsp;&nbsp;
		
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
		
	</div>
	<div class="footer-two-1">
	<b><small>友情链接</small></b>
					
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
			<br><a href="http://www.yushuai.me/" title="小奥の专属领地" target="_blank">小奥の专属领地</a>&nbsp;&nbsp;
		
				
				
			<br><a href="https://www.zning.net.cn/" title="张宁网" target="_blank">张宁网</a>&nbsp;&nbsp;
		
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
		
	</div>
	<div class="footer-three">
			<div class="footer-qrcode">
			<img src="http://tool.oschina.net/action/qrcode/generate?data=http://www.suzhengpeng.com/hello-pytorch-01&output=image%2Fgif&error=L&type=0&margin=0&size=4">
			</div>

			<br>


	</div>


</div>
</span>



 </footer>
	-->
 <a href="/"><div class="footer-ico">
</div></a>
<br><br>
	<div id="nav-list">
		<!-- Nav pages -->

		
	    
		
			<a href="/pages/page/about" title="关于博主">关于博主</a>&nbsp;&nbsp;
		
	    
		
	    
		
			<a href="/pages/page/contact" title="联系方式">联系方式</a>&nbsp;&nbsp;
		
	    
		
			<a href="/pages/page/copyright" title="版权声明">版权声明</a>&nbsp;&nbsp;
		
	    
		
	    
		
	    
		
	    
		
	    
		
	    
		
	    
		
	    
		
	    
		
	    
		
	    
		
	    
		
	    
		
	    
		
	    
		
	    
		
	    
		
	    
		
	    
		
	    
		
	    
		
	    
		
	    
		
	    
		
	    
		
	    
		
	    
		
	    
		
	    
		
	    
		
	    
		
	    
		
	    
		
	    
		
	    
		
	    
		
	    
		
	    
		
	    
		
	    
		
	    
		
	    
		
	    
		
	    
		<br>

	 <br>Suzhengpeng.COM<br><br>
	 <div class="footer-power">
		Proudly hosted by Github and powered by Jekyll <br> All designed by Suzhengpeng.COM  <br><br>
</div>
    </div>


 <!-- <div class="footer-ico-con">
 <table><tr>
<td><a href="http://space.bilibili.com/15155880" target="_blank"><img src="/img/ico/bilibili.ico"/></a> </td>
<td><a href="https://github.com/suzhengpeng" target="_blank"><img src="/img/ico/github.ico"/></a> </td>
<td><a href="http://weibo.com/sdustem" target="_blank"><img src="/img/ico/weibo.ico"/></a> </td>
<td><a href="https://www.douban.com/people/imsus/" target="_blank"><img src="/img/ico/douban.ico"/></a> </td>
<td><script type="text/javascript">var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan id='cnzz_stat_icon_1261868763'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s4.cnzz.com/z_stat.php%3Fid%3D1261868763%26show%3Dpic1' type='text/javascript'%3E%3C/script%3E"));</script></td>
</tr></table>
</div>  -->


<small>
		
				
	  		
				
	  		
				
	  		
				
	  		
				
	  		
				
	  		
				
			<a href="/pages/data/link" title="常用链接">常用链接</a>&nbsp;&nbsp;
		
	  		
				
	  		
				
	  		
				
	  		
				
	  		
				
	  		
				
	  		
				
	  		
				
	  		
				
	  		
				
	  		
				
	  		
				
	  		
				
	  		
				
	  		
				
	  		
				
	  		
				
	  		
				
	  		
				
	  		
				
	  		
				
	  		
				
	  		
				
	  		
				
	  		
				
	  		
				
	  		
				
	  		
				
	  		
				
	  		
				
	  		
				
	  		
				
	  		
				
	  		
				
	  		
				
	  		
				
	  		
				
	  		
				
	  		
				
	  		
				
	  		
				
	  
	 <br> 
</small>
 
<br>
	</nav>
    
    <!-- Icon menu -->
	  <a id="nav-menu">
	  	<div id="menu"></div>
	  </a>

      <!-- Header -->
      
        <header id="header" class="parent justify-spaceBetween">
  <div class="inner w100 relative">
    <div class="f-logo">  
      <a href="/">
        <h1>
          <span>Su</span>'S Blog
        </h1>
      </a>
    </div>

  </div>
</header>




      

    <!-- Main content -->
	  <div id="container">
		  
		<main>

			<article id="post-page">
		<!-- Oct 20, 2018 -->
		
		<!--  -->
		<br>
		&nbsp;&nbsp;<small  id="posts-relat-data"> <a href="#">Oct 20, 2018</a></small> 
		<small id="posts-relat-source"> <a href="#">原创文章 </a></small>
	<br>
	<!-- <br> -->
	<h3>&nbsp;&nbsp;Hello Pytorch 壹 -- 卷积层原理及实现   </h3>
	<!-- JiaThis Button BEGIN -->
	
<div style="padding: 10px; background:#fff;">

	<div style="position: relative; 
				border: 2px solid #E9F01D; 
				padding: 10px; 
				padding-bottom:20px;
				width:60%;
				min-width:300px;
				background:#E9F01D;
				color:#404040;
				border-radius:4px;
				" >
		<span style="position: absolute; 
					left: 30px; top: -32px; 
					width: 0; height: 0; 
					font-size: 0; 
					border-width: 16px; 
					border-style: dashed dashed solid dashed; 
					border-color: transparent transparent #E9F01D transparent;" ></span>
<div class="bshare-custom"><div class="bsPromo bsPromo2"></div>
Pytorch 框架的卷积层模块代码阅读笔记<br><br> 
分享到：<a title="分享到微信" class="bshare-weixin"></a>
<a title="分享到新浪微博" class="bshare-sinaminiblog"></a>
<a title="分享到Facebook" class="bshare-facebook"></a>
<a title="分享到Twitter" class="bshare-twitter"></a>
<a title="分享到QQ好友" class="bshare-qqim" href="javascript:void(0);"></a>
<a title="分享到豆瓣" class="bshare-douban"></a>
<a title="分享到人人网" class="bshare-renren"></a>
<a title="更多平台" class="bshare-more bshare-more-icon more-style-addthis"></a>
<span class="BSHARE_COUNT bshare-share-count">0</span>
<br><br> 请保证您的浏览器支持MathJax插件，以免数学公式无法显示</div>
<script type="text/javascript" charset="utf-8" src="http://static.bshare.cn/b/buttonLite.js#style=-1&amp;uuid=b17f1493-0201-428b-be37-0724d8ab69a2&amp;pophcol=3&amp;lang=zh"></script>
<script type="text/javascript" charset="utf-8" src="http://static.bshare.cn/b/bshareC0.js"></script>
	</div>
</div>

<!-- JiaThis Button END -->
<br>
	<div class="content">
			
		<ul id="markdown-toc">
  <li><a href="#卷积与互相关计算" id="markdown-toc-卷积与互相关计算">卷积与互相关计算</a></li>
  <li><a href="#卷积" id="markdown-toc-卷积">卷积</a>    <ul>
      <li><a href="#动画演示" id="markdown-toc-动画演示">动画演示</a></li>
      <li><a href="#二维卷积-torchnnconv2d" id="markdown-toc-二维卷积-torchnnconv2d">二维卷积 torch.nn.Conv2d</a></li>
      <li><a href="#一维卷积-torchnnconv1d" id="markdown-toc-一维卷积-torchnnconv1d">一维卷积 torch.nn.Conv1d</a></li>
      <li><a href="#三维卷积-torchnnconv3d" id="markdown-toc-三维卷积-torchnnconv3d">三维卷积 torch.nn.Conv3d</a></li>
    </ul>
  </li>
  <li><a href="#反卷积转置卷积" id="markdown-toc-反卷积转置卷积">反卷积（转置卷积）</a>    <ul>
      <li><a href="#动画演示-1" id="markdown-toc-动画演示-1">动画演示</a></li>
      <li><a href="#二维反卷积-torchnnconvtranspose2d" id="markdown-toc-二维反卷积-torchnnconvtranspose2d">二维反卷积 torch.nn.ConvTranspose2d</a></li>
      <li><a href="#一维反卷积-torchnnconvtranspose1d" id="markdown-toc-一维反卷积-torchnnconvtranspose1d">一维反卷积 torch.nn.ConvTranspose1d</a></li>
      <li><a href="#三维反卷积-torchnnconvtranspose3d" id="markdown-toc-三维反卷积-torchnnconvtranspose3d">三维反卷积 torch.nn.ConvTranspose3d</a></li>
    </ul>
  </li>
</ul>

<hr />

<blockquote>
  <p>代码：https://pytorch.org/docs/stable/_modules/torch/nn/modules/conv.html <br />
官方文档：https://pytorch.org/docs/stable/nn.html#convolution-layers  <br />
动画演示：https://github.com/vdumoulin/conv_arithmetic</p>
</blockquote>

<h3 id="卷积与互相关计算">卷积与互相关计算</h3>

<p>在深度学习领域，卷积定义为图像矩阵和卷积核的按位点乘，实质这种操作是互相关运算，而卷积需要把卷积核顺时针旋转180度然后再做点乘。</p>

<p>参见：https://en.wikipedia.org/wiki/Cross-correlation</p>

<p><img width="400px" src="/img/201810/Comparison_convolution_correlation.svg" /></p>

<center>卷积、互相关和自相关的比较</center>

<p>在信号处理领域，互相关计算可以用来计算两个信号之间的相似性，也通过与已知信号比较用于寻找未知信号中的特性。</p>

<h3 id="卷积">卷积</h3>

<h4 id="动画演示">动画演示</h4>
<center>
<table style="table-layout:fixed;">
  <tr>
    <td><img width="100px" src="https://raw.githubusercontent.com/vdumoulin/conv_arithmetic/master/gif/no_padding_no_strides.gif" /></td>
    <td><img width="100px" src="https://raw.githubusercontent.com/vdumoulin/conv_arithmetic/master/gif/arbitrary_padding_no_strides.gif" /></td>
  </tr>
  <tr>
    <td>No padding, no strides</td>
    <td>Arbitrary padding, no strides</td>
  </tr>
  <tr>
    <td><img width="100px" src="https://raw.githubusercontent.com/vdumoulin/conv_arithmetic/master/gif/same_padding_no_strides.gif" /></td>
    <td><img width="100px" src="https://raw.githubusercontent.com/vdumoulin/conv_arithmetic/master/gif/full_padding_no_strides.gif" /></td>
  </tr>
  <tr>
    <td>Half padding, no strides</td>
    <td>Full padding, no strides</td>
  </tr>
  <tr>
    <td><img width="100px" src="https://raw.githubusercontent.com/vdumoulin/conv_arithmetic/master/gif/no_padding_strides.gif" /></td>
    <td><img width="100px" src="https://raw.githubusercontent.com/vdumoulin/conv_arithmetic/master/gif/padding_strides.gif" /></td>
  </tr>
  <tr>
    <td>No padding, strides</td>
    <td>Padding, strides</td>
  </tr>
    <tr>
    <td><img width="100px" src="https://raw.githubusercontent.com/vdumoulin/conv_arithmetic/master/gif/padding_strides_odd.gif" /></td>
    <td></td>
  </tr>
  <tr>
    <td>Padding, strides (odd)</td>
    <td></td>
  </tr>
</table>
</center>
<p>N.B.: Blue maps are inputs, and cyan maps are outputs.</p>

<h4 id="二维卷积-torchnnconv2d">二维卷积 torch.nn.Conv2d</h4>

<p>class <strong>torch.nn.Conv2d</strong> (in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True)</p>

<p>输入数据大小：$(N, C_{in}, H, W)$</p>

<p>输出数据大小：$(N, C_{out}, H_{out}, W_{out})$</p>

<p>2D 卷积的整个过程以下式表达：</p>

<script type="math/tex; mode=display">\begin{equation*}
\text{out}(N_i, C_{out_j}) = \text{bias}(C_{out_j}) +
                        \sum_{k = 0}^{C_{in} - 1} \text{weight}(C_{out_j}, k) \star \text{input}(N_i, k)
\end{equation*}</script>

<p>其中 $\star$ 是 2D 互相关操作符, N 表示批（batch）的大小, C 表示通道数, H 输入数据的高（像素）, and W 表示数据的宽（像素）</p>

<p><strong>其他参数</strong></p>

<p>kernel_size (int or tuple)  :  控制卷积核的大小。</p>

<p>stride (int or tuple, optional)  ： 控制互相关的步长。</p>

<p>padding (int or tuple, optional)  ： 控制两侧隐式零填充的数量，以填充每个维度的点数。</p>

<p>dilation (int or tuple, optional)  ： 控制卷积核核点之间的间距。具体操作过程如下图所示，可以很好地显示扩张的作用</p>

<p><img width="200px" src="https://github.com/vdumoulin/conv_arithmetic/raw/master/gif/dilation.gif" /></p>
<center>卷积示意图：No padding, no stride, dilation</center>

<p>groups (int, optional) ： 控制输入和输出的连接。输入数据和输出数据的通道数必须同时被groups整除。例如：groups=1时，所有的输入卷积到所有的输出。groups=2时，有两个并列的卷积层，每个卷积层对应输入数据一半的通道数，同时也对应输出数据一半的通道数。groups= in_channels （输入数据的通道数）时 每个输入通道与对应的大小为 $\left\lfloor\frac{\text{out_channels}}{\text{in_channels}}\right\rfloor$ 的滤波器集合做卷积运算 。</p>

<p>深度卷积：当 groups == in_channels，out_channels == K * in_channels （其中K为正整数）时，被称为深度卷积。</p>

<p>输入数据大小：$(N, C_{in}, H_{in}, W_{in})$</p>

<p>输出数据大小：$(N, C_{out}, H_{out}, W_{out})$</p>

<p>其中：</p>

<script type="math/tex; mode=display">H_{out} = \left\lfloor\frac{H_{in}  + 2 \times \text{padding}[0] - \text{dilation}[0]
                        \times (\text{kernel_size}[0] - 1) - 1}{\text{stride}[0]} + 1\right\rfloor</script>

<div class="highlighter-rouge">$$           W_{out} = \left\lfloor\frac{W_{in}  + 2 \times \text{padding}[1] - \text{dilation}[1]
                    \times (\text{kernel_size}[1] - 1) - 1}{\text{stride}[1]} + 1\right\rfloor $$
</div>

<h4 id="一维卷积-torchnnconv1d">一维卷积 torch.nn.Conv1d</h4>

<p>class <strong>torch.nn.Conv1d</strong> (in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True)</p>

<p>输入数据大小：$(N, C_{in}, L)$</p>

<p>输出数据大小： $(N, C_{out}, L_{out})$</p>

<p>1D 卷积的整个过程以下式表达：</p>

<script type="math/tex; mode=display">\begin{equation*}
        \text{out}(N_i, C_{out_j}) = \text{bias}(C_{out_j}) +
                                \sum_{k = 0}^{C_{in} - 1} \text{weight}(C_{out_j}, k) \star \text{input}(N_i, k)
        \end{equation*}</script>

<p>其中 $\star$ 是 1D 互相关操作符, N 表示批（batch）的大小, C 表示通道数, L表示一维数据的长度。</p>

<blockquote>
  <p>多通道一维数据：<br />
一维卷积常用于序列模型，自然语言处理领域。以声音为例，在同一维度上，不同的通道可以表示不同的音源的声音，通道1：人声，通道2：鼓声。即：不同的通道表示不同属性的一维序列数据。</p>
</blockquote>

<p>关于一维卷积其余的属性和算法和下文中的二维卷积相似。</p>

<h4 id="三维卷积-torchnnconv3d">三维卷积 torch.nn.Conv3d</h4>

<p>class <strong>torch.nn.Conv3d</strong> (in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True)</p>

<p>相比于二维卷积，三维卷积的输入和输出是三维数据。输入数据的大小为：$(N, C_{in}, D, H, W)$，输出数据的大小为：$(N, C_{out}, D_{out}, H_{out}, W_{out})$</p>

<p>其余的概念和算法与二维卷积相同。</p>

<blockquote>
  <p>三维卷积的应用场景：
三维卷积常用于医学领域（CT影响），视频处理领域（检测动作及人物行为）</p>
</blockquote>

<h3 id="反卷积转置卷积">反卷积（转置卷积）</h3>

<p>卷积操作的作用类似神经网络中的编码器，用于对高维数据进行低维特征提取，而 <strong>反卷积</strong> 通常用于将低维特征映射成高维输入，与卷积操作的作用相反。同时也是一种基于学习的上采样实现方法。</p>

<h4 id="动画演示-1">动画演示</h4>

<center>
<table style="table-layout:fixed;">

 <tr>
    <td><img width="100px" src="https://github.com/vdumoulin/conv_arithmetic/raw/master/gif/no_padding_no_strides_transposed.gif" /></td>
    <td><img width="100px" src="https://github.com/vdumoulin/conv_arithmetic/raw/master/gif/arbitrary_padding_no_strides_transposed.gif" /></td>
  </tr>
  <tr>
    <td>No padding, no strides, transposed</td>
    <td>Arbitrary padding, no strides, transposed</td>
  </tr>
   <tr>
    <td><img width="100px" src="https://github.com/vdumoulin/conv_arithmetic/raw/master/gif/same_padding_no_strides_transposed.gif" /></td>
    <td><img width="100px" src="https://github.com/vdumoulin/conv_arithmetic/raw/master/gif/full_padding_no_strides_transposed.gif" /></td>
  </tr>
  <tr>
    <td>Half padding, no strides, transposed</td>
    <td>Full padding, no strides, transposed</td>
  </tr>
   <tr>
    <td><img width="100px" src="https://github.com/vdumoulin/conv_arithmetic/raw/master/gif/no_padding_strides_transposed.gif" /></td>
    <td><img width="100px" src="https://github.com/vdumoulin/conv_arithmetic/raw/master/gif/padding_strides_transposed.gif" /></td>
  </tr>
  <tr>
    <td>No padding, strides, transposed</td>
    <td>Padding, strides, transposed</td>
  </tr>
   <tr>
    <td><img width="100px" src="https://github.com/vdumoulin/conv_arithmetic/raw/master/gif/padding_strides_odd_transposed.gif" /></td>
    <td></td>
  </tr>
  <tr>
    <td>Padding, strides, transposed (odd)</td>
    <td></td>
  </tr>
</table></center>

<p>N.B.: Blue maps are inputs, and cyan maps are outputs.</p>

<h4 id="二维反卷积-torchnnconvtranspose2d">二维反卷积 torch.nn.ConvTranspose2d</h4>

<p>class <strong>torch.nn.ConvTranspose2d</strong> (in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1)</p>

<p>反卷积和卷积在参数上的区别在于padding和output_padding。</p>

<p><strong>padding</strong> ：控制0填充的大小。在输入数据的每个边隐式地添加 (kernel_size - 1 - padding) 个0。而在进行卷积操作时，需要填充的是(padding)个0。</p>

<p><strong>output_padding</strong> Additional size added to one side of each dimension in the output shape</p>

<p>The padding argument effectively adds kernel_size - 1 - padding amount of zero padding to both sizes of the input. This is set so that when a Conv3d and a ConvTranspose3d are initialized with same parameters, they are inverses of each other in regard to the input and output shapes. However, when stride &gt; 1, Conv3d maps multiple input shapes to the same output shape. output_padding is provided to resolve this ambiguity by effectively increasing the calculated output shape on one side. Note that output_padding is only used to find output shape, but does not actually add zero-padding to output.</p>

<p>输入数据大小：$(N, C_{in}, H_{in}, W_{in})$</p>

<p>输出数据大小：$(N, C_{out}, H_{out}, W_{out})$</p>

<p>其中：</p>

<script type="math/tex; mode=display">H_{out} = (H_{in} - 1) \times \text{stride}[0] - 2 \times \text{padding}[0]
                    + \text{kernel_size}[0] + \text{output_padding}[0]</script>

<script type="math/tex; mode=display">W_{out} = (W_{in} - 1) \times \text{stride}[1] - 2 \times \text{padding}[1]
                    + \text{kernel_size}[1] + \text{output_padding}[1]</script>

<h4 id="一维反卷积-torchnnconvtranspose1d">一维反卷积 torch.nn.ConvTranspose1d</h4>

<p>class <strong>torch.nn.ConvTranspose1d</strong> (in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1)</p>

<p>在计算方法和参数设置上与二维反卷积相似。</p>

<h4 id="三维反卷积-torchnnconvtranspose3d">三维反卷积 torch.nn.ConvTranspose3d</h4>

<p>class <strong>torch.nn.ConvTranspose3d</strong> (in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1)</p>

<p>在计算方法和参数设置上与二维反卷积相似。</p>

<!-- ### 张量折叠和展开

#### 折叠 torch.nn.Unfold

class __torch.nn.Unfold__ (kernel_size, dilation=1, padding=0, stride=1)

Extracts sliding local blocks from a batched input tensor.

设有一批输入张量的形状为$(N, C, *)$，其中N为批维度，C为通道维度，$*$表示任意的空间维度。通过这种操作将输入的张量在滑过大小为 kernel_size 大小的块（block）后折叠为形状大小为$(N, C \times \prod(\text{kernel_size}), L)$的张量，其中：$C \times \prod(\text{kernel_size})$为每一个块（block）中数值的个数（每个块中共有$\prod(\text{kernel_size})$个空间位置，每个位置为有C个通道的向量）。

#### 展开 torch.nn.fold

class __torch.nn.Fold__ (output_size, kernel_size, dilation=1, padding=0, stride=1)

Combines an array of sliding local blocks into a large containing tensor. -->

<!-- <pre>
<code class="python">

</code>
</pre> -->

<!-- ----

__参考资料：__

1、__opencv中GPU的流操作__ https://blog.csdn.net/eyes366/article/details/48438397

2、__how to use gpu::Stream in OpenCV?__ https://stackoverflow.com/questions/17842827/how-to-use-gpustream-in-opencv
 -->

<hr />

		
	</div>
	<div id="posts-out-tags"># <a href="/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0.html" rel="tag">深度学习</a>, <a href="/tag/pytorch.html" rel="tag">Pytorch</a>, <a href="/tag/%E5%8D%B7%E7%A7%AF%E5%B1%82.html" rel="tag">卷积层</a> <a href="/tags.html" class="set-1">>></a></div> 



	<div class="shang_con">
			<p><a href="javascript:void(0)" onclick="dashangToggle()" class="dashang" title="打赏，支持一下">打赏</a></p>
			<div class="shang_hide_box"></div>
			<div class="shang_box">
					<br>
				<div class="shang_tit">
					<p>感谢您的支持，我会继续努力的!</p>
				</div>
				<div class="shang_payimg">
					<img src="img/ds/alipayimg.jpg" alt="扫码支持" title="扫一扫" />
				</div>
				<div class="shang_payselect">
					<div class="pay_item checked" data-id="alipay">
						<span class="radiobox"></span>
						<span class="pay_logo"><img src="img/ds/alipay.jpg" alt="支付宝" /></span>
					</div>
					<div class="pay_item" data-id="weipay">
						<span class="radiobox"></span>
						<span class="pay_logo"><img src="img/ds/wechat.jpg" alt="微信" /></span>
					</div>
				</div>
				<br>
				<div class="shang_info">
					<p>长按识别二维码或打开<span id="shang_pay_txt">支付宝</span>扫一扫 完成打赏<br>
					或 使用<a href="HTTPS://QR.ALIPAY.COM/FKX08963JL6LVJZYLYGZ13" ><支付宝链接></a>打赏
				</p>

				</div>
				<br>
		
				<center><a class="shang_close" href="javascript:void(0)" onclick="dashangToggle()" title="关闭">关闭</a></center>
			</div>
			</div>
			
			<script type="text/javascript">
			$(function(){
				$(".pay_item").click(function(){
					$(this).addClass('checked').siblings('.pay_item').removeClass('checked');
					var dataid=$(this).attr('data-id');
					$(".shang_payimg img").attr("src","img/ds/"+dataid+"img.jpg");
					$("#shang_pay_txt").text(dataid=="alipay"?"支付宝":"微信");
				});
			});
			function dashangToggle(){
				$(".shang_hide_box").fadeToggle();
				$(".shang_box").fadeToggle();
			}
			</script>

<div style="position: relative; 
/* border: 2px solid #E9F01D;  */
padding: 10px; 
padding-bottom:20px;
/* width:80%;
min-width:300px; */
/* background:#E9F01D; */
color:#404040;
border-radius:4px;
" >
<div class="bsPromo bsPromo2"></div>
		
		
			
			
				
					
						
					
						
					
						
					
				
			
	
			
		
			
			
				
					
						
					
						
					
						
					
				
			
				
					
						
					
						
					
						
					
				
			
	
			
		
			
			
				
					
						
					
						
					
						
					
				
			
				
					
						
					
						
					
						
					
				
			
	
			
		
			
			
				
					
						
							
								<h5 class="page-heading">相关文章:</h5>	
							
							
	
						<small><a href="/hello-pytorch-04">Hello Pytorch 肆 -- 激活函数</a> </small> 
						<small id="posts-out-tags"># <a href="/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0.html" rel="tag">深度学习</a>, <a href="/tag/pytorch.html" rel="tag">Pytorch</a>, <a href="/tag/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0.html" rel="tag">激活函数</a> </small> 
						 <small  id="posts-relat-data"> <a href="#">Nov 02, 2018</a></small>
						    
						 <small id="posts-relat-source"> <a href="#">原创文章 </a></small> 
						
						<br>
						
						
					
						
					
						
					
				
			
				
			
				
			
	
			
		
			
			
				
					
						
							
							
	
						<small><a href="/hello-pytorch-03">Hello Pytorch 叁 -- 简单理解生成对抗网络（GAN）</a> </small> 
						<small id="posts-out-tags"># <a href="/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0.html" rel="tag">深度学习</a>, <a href="/tag/pytorch.html" rel="tag">Pytorch</a>, <a href="/tag/%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C.html" rel="tag">生成对抗网络</a>, <a href="/tag/gan.html" rel="tag">GAN</a> </small> 
						 <small  id="posts-relat-data"> <a href="#">Oct 29, 2018</a></small>
						    
						 <small id="posts-relat-source"> <a href="#">原创文章 </a></small> 
						
						<br>
						
						
					
						
					
						
					
				
			
				
			
				
			
				
			
	
			
		
			
			
				
					
						
							
							
	
						<small><a href="/hello-pytorch-02">Hello Pytorch 贰 -- 常用损失函数</a> </small> 
						<small id="posts-out-tags"># <a href="/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0.html" rel="tag">深度学习</a>, <a href="/tag/pytorch.html" rel="tag">Pytorch</a>, <a href="/tag/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0.html" rel="tag">损失函数</a>, <a href="/tag/%E4%BA%A4%E5%8F%89%E7%86%B5.html" rel="tag">交叉熵</a> </small> 
						 <small  id="posts-relat-data"> <a href="#">Oct 20, 2018</a></small>
						    
						 <small id="posts-relat-source"> <a href="#">原创文章 </a></small> 
						
						<br>
						
						
					
						
					
						
					
				
			
				
			
				
			
				
			
	
			
		
			
			
				
					
						
							
							
	
						<small><a href="/hello-pytorch-00">Hello Pytorch 零 -- 搭建年轻人的第一个神经网络：LeNet</a> </small> 
						<small id="posts-out-tags"># <a href="/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0.html" rel="tag">深度学习</a>, <a href="/tag/pytorch.html" rel="tag">Pytorch</a>, <a href="/tag/lenet.html" rel="tag">LeNet</a>, <a href="/tag/cifar-10.html" rel="tag">CIFAR-10</a>, <a href="/tag/cnn.html" rel="tag">CNN</a> </small> 
						 <small  id="posts-relat-data"> <a href="#">Oct 19, 2018</a></small>
						    
						 <small id="posts-relat-source"> <a href="#">原创文章 </a></small> 
						
						<br>
						
						
					
						
					
						
					
				
			
				
			
				
			
				
			
				
			
	
			
		
			
			
				
					
						
					
						
					
						
					
				
			
				
					
						
					
						
					
						
					
				
			
				
					
						
					
						
					
						
					
				
			
	
			
		
			
			
				
					
						
					
						
					
						
					
				
			
				
					
						
					
						
					
						
					
				
			
				
					
						
					
						
					
						
					
				
			
				
					
						
					
						
					
						
					
				
			
	
			
		
			
			
				
					
						
					
						
					
						
					
				
			
				
					
						
					
						
					
						
					
				
			
				
					
						
					
						
					
						
					
				
			
	
			
		
	
		
		<!-- </ul> -->
		

		<br>
		

		<div class="bshare-custom">
			<!-- <div class="bsPromo bsPromo2"></div> -->
分享到：<a title="分享到微信" class="bshare-weixin"></a>
<a title="分享到新浪微博" class="bshare-sinaminiblog"></a>
<a title="分享到Facebook" class="bshare-facebook"></a>
<a title="分享到Twitter" class="bshare-twitter"></a>
<a title="分享到QQ好友" class="bshare-qqim" href="javascript:void(0);"></a>
<a title="分享到豆瓣" class="bshare-douban"></a>
<a title="分享到人人网" class="bshare-renren"></a>
<a title="更多平台" class="bshare-more bshare-more-icon more-style-addthis"></a>
<span class="BSHARE_COUNT bshare-share-count">0</span>
</div>
<script type="text/javascript" charset="utf-8" src="http://static.bshare.cn/b/buttonLite.js#style=-1&amp;uuid=b17f1493-0201-428b-be37-0724d8ab69a2&amp;pophcol=3&amp;lang=zh"></script>
<script type="text/javascript" charset="utf-8" src="http://static.bshare.cn/b/bshareC0.js"></script>
	

	</div>

</article>



	  </main>
		
		  <!-- Pagination links -->
      

	  </div>
	    
	    <!-- Footer -->
	    <footer><span>

<div class="footer" id="nav-links">

	<div class="footer-one">
	
		<div class="footer-ico"></div>
		<br>
		Suzhengpeng.COM
		<br>
			 <div class="footer-power">
		Proudly hosted by Github and powered by Jekyll <br> All designed by Suzhengpeng.COM </div>
		<br>
	
	</div>
	
	<div class="footer-two">
	
		

	    
		
			<a href="/pages/page/about" title="关于博主">关于博主</a>&nbsp;&nbsp;<br>
		

	    
		

	    
		
			<a href="/pages/page/contact" title="联系方式">联系方式</a>&nbsp;&nbsp;<br>
		

	    
		
			<a href="/pages/page/copyright" title="版权声明">版权声明</a>&nbsp;&nbsp;<br>
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		

	    
		<br>

	</div>
	<div class="footer-two">
					
				
				
				
				
				
				
				
				
				
				
				
				
				
			<a href="/pages/data/link" title="常用链接">常用链接</a>&nbsp;&nbsp;
		
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
		
	</div>
	<div class="footer-two-1">
	<b><small>友情链接</small></b>
					
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
			<br><a href="http://www.yushuai.me/" title="小奥の专属领地" target="_blank">小奥の专属领地</a>&nbsp;&nbsp;
		
				
				
			<br><a href="https://www.zning.net.cn/" title="张宁网" target="_blank">张宁网</a>&nbsp;&nbsp;
		
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				
		
	</div>
	<div class="footer-three">
			<div class="footer-qrcode">
			<img src="http://tool.oschina.net/action/qrcode/generate?data=http://www.suzhengpeng.com/hello-pytorch-01&output=image%2Fgif&error=L&type=0&margin=0&size=4">
			</div>

			<br>


	</div>


</div>
</span>



 </footer>

	    <!-- Script -->
      <script src="/js/main.js"></script>

	


	</div>
</body>
</html>
