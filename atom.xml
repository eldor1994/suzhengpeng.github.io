<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

 <title>Suzhengpeng'S Blog</title>
 <link href="http://localhost:4000/atom.xml" rel="self"/>
 <id>http://localhost:4000</id>
 <updated>2018-12-25T15:23:25+08:00</updated>
 <author>
   <name>Su Zhengpeng</name>
   <uri></uri>
   <email>suzhengpeng@hotmail.com</email>
 </author>

 

 <entry>
   <title>计算机视觉基本知识：等距圆柱投影法 Equidistant Cylindrical Projection</title>
   <link href="http://localhost:4000/cvabc-01"/>
   <id>http://localhost:4000/cvabc-01</id>
   <updated>2018-12-22T00:00:00+08:00</updated>
   <content type="html">&lt;!-- * 索引 {:toc} --&gt; &lt;!-- ---- --&gt; &lt;h3 id=&quot;等距圆柱投影法&quot;&gt;等距圆柱投影法&lt;/h3&gt; &lt;p&gt;&lt;img width=&quot;500px&quot; src=&quot;/img/201812/1.jpg&quot; /&gt;&lt;/p&gt; &lt;center&gt;等距圆柱投影法示意图&lt;/center&gt; &lt;p&gt;等距圆柱投影（equidistant cylindrical projection）是一种简单的地图投影方法，在这种投影方法中：假设球面和圆柱面相切于赤道, 将球面上的经纬线投影到圆柱面上, 然后沿圆柱面的一条母线展开成平面的一种投影。&lt;/p&gt; &lt;h3 id=&quot;投影坐标换算&quot;&gt;投影坐标换算&lt;/h3&gt; &lt;p&gt;假设鱼眼图的大小Hd Wd，将其使用等距圆柱投影法投影到大小为Hs Ws的矩形图内。&lt;/p&gt; &lt;h4 id=&quot;在矩形图中建立经纬度笛卡尔坐标系统&quot;&gt;在矩形图中建立经纬度笛卡尔坐标系统&lt;/h4&gt; &lt;p&gt;代码示例：&lt;/p&gt; &lt;blockquote&gt; &lt;p&gt;ys, xs = np.indices((Hs, Ws), np.float32)&lt;br /&gt; y_proj = Hs / 2.0 - ys&lt;br /&gt; x_proj = xs - Ws /...</content>
 </entry>

 

 <entry>
   <title>理解 Long Short-term Memory 长短期记忆网络</title>
   <link href="http://localhost:4000/LSTM"/>
   <id>http://localhost:4000/LSTM</id>
   <updated>2018-11-15T00:00:00+08:00</updated>
   <content type="html">&lt;ul id=&quot;markdown-toc&quot;&gt; &lt;li&gt;&lt;a href=&quot;#递归循环神经网络-recurrent-neural-networks&quot; id=&quot;markdown-toc-递归循环神经网络-recurrent-neural-networks&quot;&gt;递归（循环）神经网络 Recurrent Neural Networks&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;#长期依赖long-term-dependencies问题&quot; id=&quot;markdown-toc-长期依赖long-term-dependencies问题&quot;&gt;长期依赖（Long-Term Dependencies）问题&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;#长短期记忆网络-long-short-term-memory&quot; id=&quot;markdown-toc-长短期记忆网络-long-short-term-memory&quot;&gt;长短期记忆网络 Long Short-term Memory&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;#lstm-的基本结构&quot; id=&quot;markdown-toc-lstm-的基本结构&quot;&gt;LSTM 的基本结构&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;#lstm-公式推导&quot; id=&quot;markdown-toc-lstm-公式推导&quot;&gt;LSTM 公式推导&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;#lstm-的变种&quot; id=&quot;markdown-toc-lstm-的变种&quot;&gt;LSTM 的变种&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;hr /&gt; &lt;h3 id=&quot;递归循环神经网络-recurrent-neural-networks&quot;&gt;递归（循环）神经网络 Recurrent Neural Networks&lt;/h3&gt; &lt;p&gt;设计递归神经网络的目的是使网络具有记忆性，如果在计算过程中需要保持对之前网络状态的记忆就使用到递归神经网络RNN。&lt;/p&gt; &lt;p&gt;&lt;img width=&quot;100px&quot; src=&quot;/img/201811/16.png&quot; /&gt;&lt;/p&gt; &lt;p&gt;如上图所示RNN具有循环结构，A表示网络结构，$x_t$为网络的输入，而$h_t$为当前时刻的网络输出。循环可以使得信息可以从当前步传递到下一步。RNN 可以被看做是同一神经网络的多次复制，每个神经网络模块会把消息传递给下一个。所以，如果我们将这个循环展开，可以得到下图：&lt;/p&gt; &lt;p&gt;&lt;img width=&quot;500px&quot; src=&quot;/img/201811/17.png&quot; /&gt;&lt;/p&gt; &lt;h3...</content>
 </entry>

 

 <entry>
   <title>Attentive Generative Adversarial Network for Raindrop Removal from A Single Image</title>
   <link href="http://localhost:4000/Attentive_Generative_Adversarial_Network_for_Raindrop_Removal_from_A_Single_Image"/>
   <id>http://localhost:4000/Attentive_Generative_Adversarial_Network_for_Raindrop_Removal_from_A_Single_Image</id>
   <updated>2018-11-09T00:00:00+08:00</updated>
   <content type="html">&lt;ul id=&quot;markdown-toc&quot;&gt; &lt;li&gt;&lt;a href=&quot;#论文摘要&quot; id=&quot;markdown-toc-论文摘要&quot;&gt;论文摘要&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;#网络设计&quot; id=&quot;markdown-toc-网络设计&quot;&gt;网络设计&lt;/a&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;#生成网络&quot; id=&quot;markdown-toc-生成网络&quot;&gt;生成网络&lt;/a&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;#注意力递归网络-attentive-recurrent-network&quot; id=&quot;markdown-toc-注意力递归网络-attentive-recurrent-network&quot;&gt;注意力递归网络 Attentive-Recurrent Network&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;#上下文自动解码器-contextual-autoencoder&quot; id=&quot;markdown-toc-上下文自动解码器-contextual-autoencoder&quot;&gt;上下文自动解码器 Contextual Autoencoder&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt;&lt;a href=&quot;#判别网络&quot; id=&quot;markdown-toc-判别网络&quot;&gt;判别网络&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;/ul&gt; &lt;hr /&gt; &lt;p&gt;&lt;strong&gt;论文下载地址&lt;/strong&gt;：http://openaccess.thecvf.com/content_cvpr_2018/papers/Qian_Attentive_Generative_Adversarial_CVPR_2018_paper.pdf&lt;/p&gt; &lt;h3 id=&quot;论文摘要&quot;&gt;论文摘要&lt;/h3&gt; &lt;p&gt;相机镜头前的雨滴会妨碍背景场景的可视性并显着降低图像质量。&lt;/p&gt; &lt;p&gt;&lt;strong&gt;现实存在的问题：&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;1、被雨滴遮挡的区域并不会事先给出。&lt;/p&gt; &lt;p&gt;2、被雨滴遮挡的背景信息是完全丢失的。&lt;/p&gt; &lt;p&gt;&lt;strong&gt;算法的核心思想：&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;在生成和分类网络中加入 视觉注意力（visual attention）。&lt;/p&gt; &lt;p&gt;在训练过程中 视觉注意力（visual attention） 学习雨滴及其周边区域，通过将这些信息加入到网络中，生成网络（generative network ）会在雨滴及其周边区域的结构上耗费更多的注意力，而判别网络（discriminative...</content>
 </entry>

 

 <entry>
   <title>Hello Pytorch 肆 -- 激活函数</title>
   <link href="http://localhost:4000/hello-pytorch-04"/>
   <id>http://localhost:4000/hello-pytorch-04</id>
   <updated>2018-11-02T00:00:00+08:00</updated>
   <content type="html">&lt;ul id=&quot;markdown-toc&quot;&gt; &lt;li&gt;&lt;a href=&quot;#sigmoid函数&quot; id=&quot;markdown-toc-sigmoid函数&quot;&gt;Sigmoid函数&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;#softmax函数&quot; id=&quot;markdown-toc-softmax函数&quot;&gt;Softmax函数&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;#tanh函数&quot; id=&quot;markdown-toc-tanh函数&quot;&gt;Tanh函数&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;#relu函数&quot; id=&quot;markdown-toc-relu函数&quot;&gt;ReLU函数&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;#leakyrelu&quot; id=&quot;markdown-toc-leakyrelu&quot;&gt;LeakyReLU&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;hr /&gt; &lt;p&gt;激活函数（Activation Function），就是在人工神经网络的神经元上运行的函数，负责将神经元的输入映射到输出端。激活函数的使用给神经元引入了非线性因素，使得神经网络可以任意逼近任何非线性函数，这样神经网络就可以应用到众多的非线性模型中。&lt;/p&gt; &lt;h3 id=&quot;sigmoid函数&quot;&gt;Sigmoid函数&lt;/h3&gt; &lt;p&gt;Sigmoid函数又叫Logistic函数，是皮埃尔·弗朗索瓦·韦吕勒在1844年在研究它与人口增长的关系时命名的。广义Logistic曲线可以模仿一些情况人口增长（P）的 S 形曲线。起初阶段大致是指数增长；然后随着开始变得饱和，增加变慢；最后，达到成熟时增加停止。&lt;/p&gt; &lt;p&gt;之所以叫Sigmoid，是因为函数的图像很想一个字母S。从图像上我们可以观察到一些直观的特性：函数的取值在0-1之间，且在0.5处为中心对称，并且越靠近x=0的取值斜率越大。&lt;/p&gt; &lt;p&gt;Sigmoid函数在物理意义上最为接近生物神经元。(0, 1) 的输出还可以被表示作概率，或用于输入的归一化，代表性的如Sigmoid交叉熵损失函数。&lt;/p&gt; &lt;p&gt;&lt;strong&gt;计算公式：&lt;/strong&gt;&lt;/p&gt; &lt;script type=&quot;math/tex; mode=display&quot;&gt;\text{Sigmoid}(x) = \frac{1}{1 + \exp(-x)}&lt;/script&gt; &lt;p&gt;&lt;strong&gt;函数图像：&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;&lt;img width=&quot;400px&quot; src=&quot;/img/201811/Sigmoid.png&quot; /&gt;&lt;/p&gt; &lt;h3 id=&quot;softmax函数&quot;&gt;Softmax函数&lt;/h3&gt; &lt;p&gt;Softmax函数，或称归一化指数函数。用于多分类过程中将多个神经元的输出，映射到（0,1）区间内。&lt;/p&gt; &lt;p&gt;&lt;strong&gt;计算公式：&lt;/strong&gt;&lt;/p&gt; &lt;script type=&quot;math/tex;...</content>
 </entry>

 

 <entry>
   <title>Hello Pytorch 叁 -- 简单理解生成对抗网络（GAN）</title>
   <link href="http://localhost:4000/hello-pytorch-03"/>
   <id>http://localhost:4000/hello-pytorch-03</id>
   <updated>2018-10-29T00:00:00+08:00</updated>
   <content type="html">&lt;ul id=&quot;markdown-toc&quot;&gt; &lt;li&gt;&lt;a href=&quot;#零和博弈思想&quot; id=&quot;markdown-toc-零和博弈思想&quot;&gt;零和博弈思想&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;#优化目标函数&quot; id=&quot;markdown-toc-优化目标函数&quot;&gt;优化目标函数&lt;/a&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;#优化方法&quot; id=&quot;markdown-toc-优化方法&quot;&gt;优化方法&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;#优化过程&quot; id=&quot;markdown-toc-优化过程&quot;&gt;优化过程&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;/ul&gt; &lt;hr /&gt; &lt;h3 id=&quot;零和博弈思想&quot;&gt;零和博弈思想&lt;/h3&gt; &lt;p&gt;GAN（生产对抗网络，Generative Adversarial Nets）的思想是是一种二人零和博弈思想（two-player game），指参与博弈的各方，在严格竞争下，一方的收益必然意味着另一方的损失，博弈各方的收益和损失相加总和永远为“零”，双方不存在合作的可能。&lt;/p&gt; &lt;p&gt;引申到GAN里面就是可以看成，GAN中有两个这样的博弈者，一个是生成模型（Generator）用来生成一张真实的图片，另一个是判别模型（Discriminator）判别一张图片是生成出来的还是真实存在的。整个博弈的过程，就变成了如下模式：生成模型生成一些图片-&amp;gt;判别模型学习区分生成的图片和真实图片-&amp;gt;生成模型根据判别模型改进自己，生成新的图片-&amp;gt;···· 这个博弈的过程直至生成模型与判别模型无法提高自己——即判别模型无法判断一张图片是生成出来的还是真实的而结束，此时生成模型就会成为一个完美的模型。这种博弈式的训练过程，如果采用神经网络作为模型类型，则被称为生成对抗网络（GAN）&lt;/p&gt; &lt;h3 id=&quot;优化目标函数&quot;&gt;优化目标函数&lt;/h3&gt; &lt;p&gt;这里设x为训练样本，z为随机噪声。训练得到的生成模型为G，判别模型为D。G(z)将这个随机噪声转化为与x具有相同数据结构的图像，D(x)为判别结果是0-1范围内的一个实数。&lt;/p&gt; &lt;p&gt;生成模型的目标是让判别模型无法区分真实图片与生成图片，那么整个的优化目标函数如下：&lt;/p&gt; &lt;p&gt;&lt;img width=&quot;500px&quot; src=&quot;/img/201810/04.jpg&quot; /&gt;&lt;/p&gt; &lt;h4 id=&quot;优化方法&quot;&gt;优化方法&lt;/h4&gt; &lt;p&gt;对这个最大最小化目标函数，最直观的处理办法就是分别对D和G进行交互迭代，固定G，优化D，一段时间后，固定D再优化G，直到过程收敛。&lt;/p&gt; &lt;p&gt;首先，固定G，优化D：&lt;/p&gt; &lt;p&gt;&lt;img width=&quot;500px&quot; src=&quot;/img/201810/05.jpg&quot; /&gt;&lt;/p&gt; &lt;p&gt;优化判别模型D的时候，与生成模型G无关，G(z)相当于已经得到的生成样本。当真实样本x（真实样本标签为1）输入的时候，希望得到的判别结果D(x)越接近于1越好，同时目标函数越大越好。对于生成样本G(z)（其标签为0），希望得到的判别结果D(G(z))越接近于0越好，也就是使1-D(G(z))越接近于1越好，而目标函数越大越好。因此将两者同时输入，希望得到的目标函数的和越大越好。&lt;/p&gt; &lt;p&gt;然后，固定D，优化G：&lt;/p&gt; &lt;p&gt;&lt;img width=&quot;400px&quot; src=&quot;/img/201810/06.jpg&quot; /&gt;&lt;/p&gt;...</content>
 </entry>

 

 <entry>
   <title>Hello Pytorch 贰 -- 常用损失函数</title>
   <link href="http://localhost:4000/hello-pytorch-02"/>
   <id>http://localhost:4000/hello-pytorch-02</id>
   <updated>2018-10-20T00:00:00+08:00</updated>
   <content type="html">&lt;ul id=&quot;markdown-toc&quot;&gt; &lt;li&gt;&lt;a href=&quot;#损失函数&quot; id=&quot;markdown-toc-损失函数&quot;&gt;损失函数&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;#l1loss-l1-范数损失函数&quot; id=&quot;markdown-toc-l1loss-l1-范数损失函数&quot;&gt;L1Loss L1-范数损失函数&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;#mseloss-均方差损失函数&quot; id=&quot;markdown-toc-mseloss-均方差损失函数&quot;&gt;MSELoss 均方差损失函数&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;#crossentropyloss-交叉熵损失函数&quot; id=&quot;markdown-toc-crossentropyloss-交叉熵损失函数&quot;&gt;CrossEntropyLoss 交叉熵损失函数&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;hr /&gt; &lt;blockquote&gt; &lt;p&gt;官方文档：https://pytorch.org/docs/stable/nn.html#loss-functions&lt;/p&gt; &lt;/blockquote&gt; &lt;h3 id=&quot;损失函数&quot;&gt;损失函数&lt;/h3&gt; &lt;p&gt;损失函数（loss function）是一个非负实值函数，用来计算模型的预测值f(x)与真实值Y的差异程度。&lt;/p&gt; &lt;h3 id=&quot;l1loss-l1-范数损失函数&quot;&gt;L1Loss L1-范数损失函数&lt;/h3&gt; &lt;p&gt;计算公式：&lt;/p&gt; &lt;script type=&quot;math/tex; mode=display&quot;&gt;\ell(x, y) = L = \{l_1,\dots,l_N\}^\top, \quad l_n = \left| x_n - y_n \right|,&lt;/script&gt; &lt;p&gt;其中 N 为batch的大小。如果...</content>
 </entry>

 

 <entry>
   <title>Hello Pytorch 壹 -- 卷积层原理及实现</title>
   <link href="http://localhost:4000/hello-pytorch-01"/>
   <id>http://localhost:4000/hello-pytorch-01</id>
   <updated>2018-10-20T00:00:00+08:00</updated>
   <content type="html">&lt;ul id=&quot;markdown-toc&quot;&gt; &lt;li&gt;&lt;a href=&quot;#卷积与互相关计算&quot; id=&quot;markdown-toc-卷积与互相关计算&quot;&gt;卷积与互相关计算&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;#卷积&quot; id=&quot;markdown-toc-卷积&quot;&gt;卷积&lt;/a&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;#动画演示&quot; id=&quot;markdown-toc-动画演示&quot;&gt;动画演示&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;#二维卷积-torchnnconv2d&quot; id=&quot;markdown-toc-二维卷积-torchnnconv2d&quot;&gt;二维卷积 torch.nn.Conv2d&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;#一维卷积-torchnnconv1d&quot; id=&quot;markdown-toc-一维卷积-torchnnconv1d&quot;&gt;一维卷积 torch.nn.Conv1d&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;#三维卷积-torchnnconv3d&quot; id=&quot;markdown-toc-三维卷积-torchnnconv3d&quot;&gt;三维卷积 torch.nn.Conv3d&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt;&lt;a href=&quot;#反卷积转置卷积&quot; id=&quot;markdown-toc-反卷积转置卷积&quot;&gt;反卷积（转置卷积）&lt;/a&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;#动画演示-1&quot; id=&quot;markdown-toc-动画演示-1&quot;&gt;动画演示&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;#二维反卷积-torchnnconvtranspose2d&quot; id=&quot;markdown-toc-二维反卷积-torchnnconvtranspose2d&quot;&gt;二维反卷积 torch.nn.ConvTranspose2d&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;#一维反卷积-torchnnconvtranspose1d&quot; id=&quot;markdown-toc-一维反卷积-torchnnconvtranspose1d&quot;&gt;一维反卷积 torch.nn.ConvTranspose1d&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;#三维反卷积-torchnnconvtranspose3d&quot; id=&quot;markdown-toc-三维反卷积-torchnnconvtranspose3d&quot;&gt;三维反卷积 torch.nn.ConvTranspose3d&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;/ul&gt; &lt;hr /&gt;...</content>
 </entry>

 

 <entry>
   <title>Hello Pytorch 零 -- 搭建年轻人的第一个神经网络：LeNet</title>
   <link href="http://localhost:4000/hello-pytorch-00"/>
   <id>http://localhost:4000/hello-pytorch-00</id>
   <updated>2018-10-19T00:00:00+08:00</updated>
   <content type="html">&lt;ul id=&quot;markdown-toc&quot;&gt; &lt;li&gt;&lt;a href=&quot;#经典网络模型lenet&quot; id=&quot;markdown-toc-经典网络模型lenet&quot;&gt;经典网络模型：LeNet&lt;/a&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;#网络结构&quot; id=&quot;markdown-toc-网络结构&quot;&gt;网络结构&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;#理解网络&quot; id=&quot;markdown-toc-理解网络&quot;&gt;理解网络&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt;&lt;a href=&quot;#cifar-10训练集&quot; id=&quot;markdown-toc-cifar-10训练集&quot;&gt;CIFAR-10训练集&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;#搭建网络&quot; id=&quot;markdown-toc-搭建网络&quot;&gt;搭建网络&lt;/a&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;#代码示例&quot; id=&quot;markdown-toc-代码示例&quot;&gt;代码示例&lt;/a&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;#导入所需的包&quot; id=&quot;markdown-toc-导入所需的包&quot;&gt;导入所需的包&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;#定义对数据的预处理&quot; id=&quot;markdown-toc-定义对数据的预处理&quot;&gt;定义对数据的预处理&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;#定义训练集&quot; id=&quot;markdown-toc-定义训练集&quot;&gt;定义训练集&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;#定义测试集&quot; id=&quot;markdown-toc-定义测试集&quot;&gt;定义测试集&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;#定义网络&quot; id=&quot;markdown-toc-定义网络&quot;&gt;定义网络&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;#定义损失函数和优化器&quot; id=&quot;markdown-toc-定义损失函数和优化器&quot;&gt;定义损失函数和优化器&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;#训练网络&quot; id=&quot;markdown-toc-训练网络&quot;&gt;训练网络&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;#测试效果&quot; id=&quot;markdown-toc-测试效果&quot;&gt;测试效果&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a...</content>
 </entry>

 

 <entry>
   <title>CUDA并行编程学习（6）-- 流</title>
   <link href="http://localhost:4000/cuda_learning_06"/>
   <id>http://localhost:4000/cuda_learning_06</id>
   <updated>2018-10-16T00:00:00+08:00</updated>
   <content type="html">&lt;ul id=&quot;markdown-toc&quot;&gt; &lt;li&gt;&lt;a href=&quot;#关于流&quot; id=&quot;markdown-toc-关于流&quot;&gt;关于流&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;#流并行&quot; id=&quot;markdown-toc-流并行&quot;&gt;流并行&lt;/a&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;#页锁内存的概念&quot; id=&quot;markdown-toc-页锁内存的概念&quot;&gt;页锁内存的概念&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;#流的运行机制&quot; id=&quot;markdown-toc-流的运行机制&quot;&gt;流的运行机制&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;#多个流的调度&quot; id=&quot;markdown-toc-多个流的调度&quot;&gt;多个流的调度&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;/ul&gt; &lt;hr /&gt; &lt;h3 id=&quot;关于流&quot;&gt;关于流&lt;/h3&gt; &lt;p&gt;在GPU上，流是执行异步并行的主要载体。在GPU上，每个流都可以看作是一个独立的任务，每个流中的代码操作顺序执行。&lt;/p&gt; &lt;p&gt;关于CPU和GPU的异步并行详见：&lt;a href=&quot;/cuda_learning_05&quot; target=&quot;_blank&quot;&gt;《CUDA并行编程学习（5）– 异步并行》&lt;/a&gt;&lt;/p&gt; &lt;h3 id=&quot;流并行&quot;&gt;流并行&lt;/h3&gt; &lt;p&gt;流并行是指我们可以创建多个流来执行多个任务， 但每个流都是一个需要按照顺序执行的操作队列。&lt;/p&gt; &lt;h4 id=&quot;页锁内存的概念&quot;&gt;页锁内存的概念&lt;/h4&gt; &lt;p&gt;&lt;strong&gt;使用页锁内存的意义&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;想要实现流并行，需要主机使用一块固定的内存，一般称之为页锁内存（Page Locked Memory），而一般情况下经过分配得到的内存为可分页内存（Pagable Memory）。而可分页内存面临着重定位的问题，因此使用可分页内存进行复制时，复制可能执行两次操作：从可分页内存复制到一块“临时”页锁定内存，然后从页锁定内存复制到GPU。&lt;/p&gt; &lt;p&gt;&lt;strong&gt;页锁内存的性质&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;页锁内存 （Page Locked Memory）又称为固定内存（Pinned Memory）或者不可分页内存。 操作系统将不会对这块内存分页并交换到磁盘上，从而确保了该内存始终驻留在物理内存中，因为这块内存将不会被破坏或者重新定位。 由于gpu知道内存的物理地址，因此可以通过“直接内存访问（Direct Memory...</content>
 </entry>

 

 <entry>
   <title>OpenCV GPU 模块学习 （2）GPU的流操作</title>
   <link href="http://localhost:4000/opencv-gpu-module-2"/>
   <id>http://localhost:4000/opencv-gpu-module-2</id>
   <updated>2018-10-14T00:00:00+08:00</updated>
   <content type="html">&lt;!-- * 索引 {:toc} --&gt; &lt;hr /&gt; &lt;blockquote&gt; &lt;p&gt;&lt;strong&gt;软件信息&lt;/strong&gt;：&lt;br /&gt; OpenCV Version : 2.4.13.6&lt;br /&gt; CUDA Version : 8.0&lt;/p&gt; &lt;/blockquote&gt; &lt;blockquote&gt; &lt;p&gt;&lt;strong&gt;OpenCV gpu::Stream 手册&lt;/strong&gt;&lt;br /&gt; https://docs.opencv.org/2.4.13.6/modules/gpu/doc/data_structures.html#gpu::Stream&lt;/p&gt; &lt;/blockquote&gt; &lt;p&gt;OpenCV 通过 gpu::Stream 类封装了一个异步调用。&lt;/p&gt; &lt;p&gt;在OpenCV的gpu模块中提供的一些函数具有附加 gpu::Stream 参数的重载，这些函数可以进行初始化工作，启动GPU核函数，并且可以在结果计算完成之前返回。&lt;/p&gt; &lt;p&gt;&lt;strong&gt;编程思想：&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;新建一个Stream队列，使用 gpu::Strean::enqueueUpload() 将需要操作的数据放入队列中，然后在队列中进行所需要的操作，可以通过gpu::Stream::queryIfComplete() 和 gpu::Stream::waitForCompletion() 判断和检测操作是否完成。等待队列中的操作完成，使用 gpu::strean::enqueueDownload() 将数据返回。相较于默认的数据传输方法，使用Stream队列实现了数据的异步调用，不需要等待数据全部上传完成后再对数据进行操作，只需要在确定所需的数据，即可在上传数据的同时对数据进行操作，达到GPU计算的同时进行GPU与CPU之间的数据交换，从而达到提升效率的目。&lt;/p&gt; &lt;p&gt;关于CPU和GPU异步并行的概念和意义详见：&lt;a href=&quot;/cuda_learning_05&quot; target=&quot;_blank&quot;&gt;《CUDA并行编程学习（5）– 异步并行》&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;strong&gt;类的内容：&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt; &lt;code...</content>
 </entry>

 

</feed>