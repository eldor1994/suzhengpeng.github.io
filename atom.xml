<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

 <title>Suzhengpeng'S Blog</title>
 <link href="http://localhost:4000/atom.xml" rel="self"/>
 <id>http://localhost:4000</id>
 <updated>2018-09-26T23:54:26+08:00</updated>
 <author>
   <name>Su Zhengpeng</name>
   <uri></uri>
   <email>suzhengpeng@hotmail.com</email>
 </author>

 

 <entry>
   <title>CUDA并行编程学习（3）-- 将CUDA并行模型扩展到二维空间</title>
   <link href="http://localhost:4000/cuda_learning_03"/>
   <id>http://localhost:4000/cuda_learning_03</id>
   <updated>2018-09-26T00:00:00+08:00</updated>
   <content type="html">&lt;ul id=&quot;markdown-toc&quot;&gt; &lt;li&gt;&lt;a href=&quot;#二维内核的启动方法&quot; id=&quot;markdown-toc-二维内核的启动方法&quot;&gt;二维内核的启动方法&lt;/a&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;#指定二维线程块的大小&quot; id=&quot;markdown-toc-指定二维线程块的大小&quot;&gt;指定二维线程块的大小&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;#计算xy方向上的线程块数&quot; id=&quot;markdown-toc-计算xy方向上的线程块数&quot;&gt;计算x，y方向上的线程块数&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;#启动内核&quot; id=&quot;markdown-toc-启动内核&quot;&gt;启动内核&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt;&lt;a href=&quot;#二维内核函数&quot; id=&quot;markdown-toc-二维内核函数&quot;&gt;二维内核函数&lt;/a&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;#典型的二维内核函数&quot; id=&quot;markdown-toc-典型的二维内核函数&quot;&gt;典型的二维内核函数&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;#计算图像数据的二维内核函数&quot; id=&quot;markdown-toc-计算图像数据的二维内核函数&quot;&gt;计算图像数据的二维内核函数&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;/ul&gt; &lt;hr /&gt; &lt;h3 id=&quot;二维内核的启动方法&quot;&gt;二维内核的启动方法&lt;/h3&gt; &lt;p&gt;设一幅图像有w列，h行。在x方向使用TX个线程，在Y方向使用TY个线程&lt;/p&gt; &lt;h4 id=&quot;指定二维线程块的大小&quot;&gt;指定二维线程块的大小&lt;/h4&gt; &lt;pre&gt; &lt;code class=&quot;cpp&quot;&gt; dim3 blockSize(TX , TY); &lt;/code&gt; &lt;/pre&gt; &lt;h4 id=&quot;计算xy方向上的线程块数&quot;&gt;计算x，y方向上的线程块数&lt;/h4&gt; &lt;pre&gt; &lt;code...</content>
 </entry>

 

 <entry>
   <title>CUDA并行编程学习（2）-- 使用CUDA计算一个数组的距离值</title>
   <link href="http://localhost:4000/cuda_learning_02"/>
   <id>http://localhost:4000/cuda_learning_02</id>
   <updated>2018-09-26T00:00:00+08:00</updated>
   <content type="html">&lt;hr /&gt; &lt;blockquote&gt; &lt;p&gt;&lt;strong&gt;代码下载：https://github.com/myurtoglu/cudaforengineers/tree/master/dist_v1_cuda&lt;/strong&gt;&lt;br /&gt; 基于《CUDA高性能并行计算》中的例程&lt;/p&gt; &lt;/blockquote&gt; &lt;pre&gt; &lt;code class=&quot;cpp&quot;&gt; #include &amp;lt;stdio.h&amp;gt; #define N 64 #define TPB 32 &lt;/code&gt; &lt;/pre&gt; &lt;pre&gt; &lt;code class=&quot;cpp&quot;&gt; int main() { const float ref = 0.5f; float *d_out = 0; cudaMalloc(&amp;amp;d_out, N*sizeof(float)); distanceKernel&amp;lt;&amp;lt;&amp;lt;N/TPB, TPB&amp;gt;&amp;gt;&amp;gt;(d_out, ref, N); cudaFree(d_out); // Free the memory return 0; } &lt;/code&gt;...</content>
 </entry>

 

 <entry>
   <title>目标跟踪（3）-- Mean-shift 与目标跟踪[1]</title>
   <link href="http://localhost:4000/visual_tracking_03"/>
   <id>http://localhost:4000/visual_tracking_03</id>
   <updated>2018-09-24T00:00:00+08:00</updated>
   <content type="html">&lt;hr /&gt; &lt;h3 id=&quot;mean-shift-算法理解&quot;&gt;Mean Shift 算法理解&lt;/h3&gt; &lt;p&gt;基本概念：沿着密度上升方向寻找聚簇点&lt;/p&gt; &lt;p&gt;&lt;img src=&quot;/img/20180923/02.png&quot; width=&quot;500&quot; /&gt;&lt;/p&gt; &lt;p&gt;设在d维空间$R_d$中，划定一个有N个样本点、半径为k的高维球区域$S_k$，初始随机确定一个中心点center，N个样本点记为集合M，认为这些点属于聚簇C。计算以中心点为起点落在球内的样本点（$x_i$）为终点的向量 。计算整个圆形空间内所有向量的和，得到一个偏移向量。将中心点center沿着shift的方向移动到偏移向量的终点，移动距离即偏移向量的模。重复移动，又得到一个新的偏移向量。如此重复下去，直到偏移向量的大小满足设定的阈值要求，以此保证收敛到概率密度最大得地方。也就是最稠密的地方。 &lt;img src=&quot;/img/20180923/03.jpg&quot; width=&quot;400&quot; /&gt;&lt;/p&gt; &lt;center&gt;计算偏移向量&lt;/center&gt; &lt;p&gt;&lt;img src=&quot;/img/20180923/04.jpg&quot; width=&quot;400&quot; /&gt;&lt;/p&gt; &lt;center&gt;移动中心点&lt;/center&gt; &lt;p&gt;&lt;img src=&quot;/img/20180923/05.jpg&quot; width=&quot;400&quot; /&gt;&lt;/p&gt; &lt;center&gt;得到最终结果：收敛到概率密度最大得地方&lt;/center&gt; &lt;!-- ### 经典Mean-shift框架 ### ASMS目标跟踪算法 Github 主页：https://github.com/vojirt/asms ASMS是VOT2015官方推荐的实时算法，平均帧率125FPS。在经典mean-shift框架下加入了尺度估计，经典颜色直方图特征，加入了两个先验(尺度不剧变+可能偏最大)作为正则项，和反向尺度一致性检查。 #### 经典MS算法存在的问题 1.在跟踪过程中位置错误时可以在MS迭代中进行自我纠正，而尺度错误则不会。 &lt;img src=&quot;/img/20180923/03.PNG&quot; width=&quot;400&quot; /&gt; &lt;center&gt;Illustration of the scale ambiguity problem 尺度歧义问题说明&lt;/center&gt;...</content>
 </entry>

 

 <entry>
   <title>目标跟踪（2）-- 常用的算法测试数据集</title>
   <link href="http://localhost:4000/visual_tracking_02"/>
   <id>http://localhost:4000/visual_tracking_02</id>
   <updated>2018-09-24T00:00:00+08:00</updated>
   <content type="html">&lt;hr /&gt; &lt;h3 id=&quot;otb50-和-otb100&quot;&gt;OTB50 和 OTB100&lt;/h3&gt; &lt;p&gt;下载地址：http://cvlab.hanyang.ac.kr/tracker_benchmark/index.html&lt;/p&gt; &lt;p&gt;OTB50拥有50个测试序列，由韩国汉阳大学计算机视觉实验室于2013年发布，因此也被称为OTB2013，而OTB100于2015年发布，亦被称为OTB2015，是对OTB50的扩充，在OTB50的基础上补充了50个新的测试序列。&lt;/p&gt; &lt;h3 id=&quot;vot-数据集&quot;&gt;VOT 数据集&lt;/h3&gt; &lt;p&gt;下载地址：http://www.votchallenge.net/index.html&lt;/p&gt; &lt;p&gt;VOT测试集由VOT目标跟踪挑战赛主办方发布，用以测试相关算法的性能，且每年都会进行更新。&lt;/p&gt; &lt;h3 id=&quot;otb和vot的区别&quot;&gt;OTB和VOT的区别&lt;/h3&gt; &lt;blockquote&gt; &lt;p&gt;OTB包括25%的灰度序列，但VOT都是彩色序列，这也是造成很多颜色特征算法性能差异的原因；两个库的评价指标不一样，具体请参考论文；VOT库的序列分辨率普遍较高，这一点后面分析会提到。对于一个tracker，如果论文在两个库(最好是OTB100和VOT2016)上都结果上佳，那肯定是非常优秀的(两个库调参你能调好，我服，认了~~)，如果只跑了一个，个人更偏向于VOT2016，因为序列都是精细标注，且评价指标更好(人家毕竟是竞赛，评价指标发过TPAMI的)，差别最大的地方，OTB有随机帧开始，或矩形框加随机干扰初始化去跑，作者说这样更加符合检测算法给的框框；而VOT是第一帧初始化去跑，每次跟踪失败(预测框和标注框不重叠)时，5帧之后重新初始化，VOT以short-term为主，且认为跟踪检测应该在一起不分离，detecter会多次初始化tracker。&lt;/p&gt; &lt;p&gt;OTB在2013年公开了，对于2013以后的算法是透明的，论文都会去调参，尤其是那些只跑OTB的论文，如果关键参数直接给出还精确到小数点后两位，建议您先实测(人心不古啊~被坑的多了)。VOT竞赛的数据库是每年更新，还动不动就重新标注，动不动就改变评价指标，对当年算法是难度比较大，所以结果相对更可靠。（相信很多人和我一样，看每篇论文都会觉得这个工作太好太重要了，如果没有这篇论文，必定地球爆炸，宇宙重启~~所以就像大家都通过历年ILSVRC竞赛结果为主线了解深度学习的发展一样，第三方的结果更具说服力，所以我也以竞赛排名+是否公开源码+实测性能为标准，优选几个算法分析）&lt;/p&gt; &lt;p&gt;引用自：https://www.zhihu.com/question/26493945/answer/156025576&lt;/p&gt; &lt;/blockquote&gt; &lt;h3 id=&quot;数据集分类&quot;&gt;数据集分类&lt;/h3&gt; &lt;p&gt;在OTB数据集中，其以手工标定的方式对测试序列进行了分类。&lt;/p&gt; &lt;table&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;分类&lt;/th&gt; &lt;th&gt;说明&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;IV&lt;/td&gt; &lt;td&gt;Illumination Variation - 光线变化 目标所在区域的光线发生显著变化&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;SV&lt;/td&gt; &lt;td&gt;Scale Variation - 尺度变化 第一帧和当前帧的边界框的比率超出范围ts，ts&amp;gt; 1（ts = 2）&lt;/td&gt; &lt;/tr&gt;...</content>
 </entry>

 

 <entry>
   <title>目标跟踪（1）-- 基于深度学习的目标跟踪</title>
   <link href="http://localhost:4000/visual_tracking_01"/>
   <id>http://localhost:4000/visual_tracking_01</id>
   <updated>2018-09-23T00:00:00+08:00</updated>
   <content type="html">&lt;hr /&gt; &lt;h3 id=&quot;使用神经网络进行特征提取&quot;&gt;使用神经网络进行特征提取&lt;/h3&gt; &lt;p&gt;卷积神经网络（CNN） 具有极高的目标特征提取与表达能力，因此将CNN应用于目标跟踪的特征提取阶段，对提高目标跟踪的精度和鲁棒性具有重要的意义。&lt;/p&gt; &lt;p&gt;&lt;img src=&quot;/img/20180923/01.png&quot; width=&quot;500&quot; /&gt;&lt;/p&gt; &lt;center&gt;卷积神经网络的基本结构图&lt;/center&gt; &lt;p&gt;卷积层作特征提取层对目标的特征在不同层次具有不同的描述能力, 卷积层越高, 图像特征分辨率越低，获得的特征也就越抽象, 相反语义信息越丰富, 利用不同卷积层目标特征的不同表达, 针对目标状态有机地结合不同卷积层信息, 对不同卷积层进行区别权重处理, 利用不同目标的描述能力, 对目标跟踪的鲁棒性与精确性有很大的提升。&lt;/p&gt; &lt;p&gt;池化层是特征映射层, 通过对每个特征映射图的局部区域进行加权求和, 增加偏置后通过一个非线性函数在池化层得到新的特征图。池化的作用是: (1) 对特征图进行降维, 避免过拟合; (2) 可以一定程度上缓解目标的形变所引起的问题。&lt;/p&gt; &lt;p&gt;全连接层用于连接所有的特征, 将输出值送给分类器 (如Softmax分类器) , 起到一个分类的作用。&lt;/p&gt; &lt;h3 id=&quot;使用神经网络模拟整个相关滤波过程&quot;&gt;使用神经网络模拟整个相关滤波过程&lt;/h3&gt; &lt;p&gt;相关滤波算法的核心思想是将目标模板与搜索区域内滑动窗口取得的图像块进行相关性匹配, 响应最大位置处对应的图像块为目标图像块。相比传统特征, 深度神经网络提取的图像卷积特征具有良好的抗干扰能力, 在大规模图像分类比赛中取得巨大的成功。&lt;/p&gt; &lt;p&gt;使用神经网络模拟相关滤波的整个过程.在相关滤波中, 需要保存模板信息并提取搜索区域特征, 因此基于相关滤波思想的网络一般都采用孪生网络 (Siamese Network) 结构, 其中一条支路保存目标模板信息, 另一条支路用于搜索区域特征提取, 最后将两部分特征进行相关操作, 得到响应图像 (Response...</content>
 </entry>

 

 <entry>
   <title>目标跟踪（0）-- 视觉目标跟踪技术难点</title>
   <link href="http://localhost:4000/visual_tracking_00"/>
   <id>http://localhost:4000/visual_tracking_00</id>
   <updated>2018-09-21T00:00:00+08:00</updated>
   <content type="html">&lt;hr /&gt;

&lt;p&gt;由于目标跟踪过程中目标与环境信息的变化导致目标特征的不断变化, 以及目标跟踪对跟踪速度与精度的要求, 导致目标跟踪存在如下几个主要难点:&lt;/p&gt;

&lt;p&gt;1) 目标外观变化。由于物体活动、非刚体形变 (如人跳跃、行走等) 导致的目标外形发生变化, 或拍摄角度变化导致的目标外观变化等。&lt;/p&gt;

&lt;p&gt;2) 尺度变化。由于拍摄距离等因素导致目标在影像中所占区域大小发生变化。&lt;/p&gt;

&lt;p&gt;3) 环境变化。由于拍摄环境 (如光照、天气等) 变化导致的目标影像成像特点等的变化。&lt;/p&gt;

&lt;p&gt;4) 目标快速运动。由于目标的快速移动导致在影像中的坐标位置发生突变, 影响目标搜索的速度和精度。&lt;/p&gt;

&lt;p&gt;5) 目标遮挡、出视野。由于拍摄中目标被其他物体遮挡导致的特征部分或全部损失以及由于拍摄时目标跳出视野重新跟踪导致的跟踪失败问题。&lt;/p&gt;

&lt;p&gt;6) 成像影响。由于红外摄像仪分辨率较低, 目标分辨率低, 边缘与目标特征不明显, 有时目标与环境差异较小以及任务设备等对焦问题等都会导致目标跟踪时特征的提取困难。&lt;/p&gt;

&lt;p&gt;上述因素对目标跟踪中的目标特征提取以及目标搜索策略具有重大影响, 在实际跟踪过程中, 较为准确地及时处理这些因素所造成的影响才能保证目标跟踪的精确性与鲁棒性。&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;参考资料：&lt;/p&gt;

&lt;p&gt;[1]葛宝义,左宪章,胡永江.视觉目标跟踪方法研究综述[J].中国图象图形学报,2018,23(08):1091-1107.&lt;/p&gt;
</content>
 </entry>

 

 <entry>
   <title>C6678 PCIE（1）-- 配置地址转换</title>
   <link href="http://localhost:4000/C6678-pcie-01"/>
   <id>http://localhost:4000/C6678-pcie-01</id>
   <updated>2018-09-21T00:00:00+08:00</updated>
   <content type="html">&lt;p&gt;&lt;img src=&quot;/img/20180919/2.jpg&quot; width=&quot;700&quot; alt=&quot;孪生网络&quot; /&gt;&lt;/p&gt;

&lt;p&gt;1、&lt;strong&gt;Outbound Address Translation&lt;/strong&gt;（OAT）&lt;/p&gt;

&lt;p&gt;存储器域访问PCI域，把设备内部地址映射到PCIE总线上。&lt;/p&gt;

&lt;p&gt;2、&lt;strong&gt;Inbound  Address Translation&lt;/strong&gt;（IAT）&lt;/p&gt;

&lt;p&gt;PCI域访问存储器域、把PCIE总线地址映射到设备内部上。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;RC访问EP&lt;/strong&gt;: RC存储器域-&amp;gt;outbound-&amp;gt;RC PCI域-&amp;gt;EP PCI域-&amp;gt;inbound-&amp;gt;EP存储器域&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;EP访问RC&lt;/strong&gt;：EP存储器域-&amp;gt;outbound-&amp;gt;EP PCI域-&amp;gt;RC PCI域-&amp;gt;inbound-&amp;gt;RC存储器域&lt;/p&gt;

&lt;p&gt;Out即出去，发起访问的一侧，须要进行outbound，去访问对端&lt;/p&gt;

&lt;p&gt;In即进来，被访问的一侧，须要进行inbound，使得对端能够访问&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;EP访问RC演示样例（蓝色箭头）&lt;/strong&gt;：&lt;/p&gt;

&lt;p&gt;（1）首先，EP须要配置outbound，RC须要inbound(一般RC端不用配)，这样就建立了EP端0x20000000到RC端0x50000000的映射&lt;/p&gt;

&lt;p&gt;（2）在RC端改动0x50000000的内容，EP端能够看到对应的变化。从EP端读/写0x20000000和从RC端读/写0x50000000，结果是一样的&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;RC访问EP演示样例（黑色箭头）&lt;/strong&gt;：&lt;/p&gt;

&lt;p&gt;（1）首先，RC端须要配置outbound(一般内核中配好)，EP端须要inbound(0x5b000000 inbound到BAR2)，这样就建立了RC端0x20100000（BAR2）到EP端0x5b000000的映射。&lt;/p&gt;

&lt;p&gt;（2）在EP端改动0x5b000000内存的内容，在RC端0x20100000能够看到对应的变化，从RC端读/写0x20100000和从EP端读/写0x5b000000，结果是一样的。&lt;/p&gt;

</content>
 </entry>

 

 <entry>
   <title>C6678 PCIE（0）-- PDK_c667x_2_0_9 测试例程</title>
   <link href="http://localhost:4000/C6678-pcie-00"/>
   <id>http://localhost:4000/C6678-pcie-00</id>
   <updated>2018-09-20T00:00:00+08:00</updated>
   <content type="html">&lt;p&gt;在DSP和FPGA的PCIe通信中，DSP常被做End Point 端使用。&lt;/p&gt; &lt;h3 id=&quot;使用命令行导入例程&quot;&gt;使用命令行导入例程&lt;/h3&gt; &lt;p&gt;C6678的Processor SDK，其中提供了相关例程的源代码、RTSC配置文件(.cfg)和一个CCS工程的创建脚本，但没有直接提供CCS工程。需要使用CCS命令行创建。&lt;/p&gt; &lt;blockquote&gt; &lt;p&gt;eclipsec -noSplash -data “F:/workspace_v7” -application com.ti.ccstudio.apps.projectCreate -ccs.name pcie_demo -ccs.outputType executable -ccs.device TMS320C66XX.TMS320C6678 -ccs.definePathVariable PDK_INSTALL_PATH C:/ti/pdk_c667x_2_0_9/packages @scope project -rtsc.target ti.targets.elf.C66 -rtsc.platform ti.platforms.evm6678 -rtsc.buildProfile release -ccs.args C:/ti/pdk_c667x_2_0_9/packages/ti/drv/pcie/example/sample/c6678/c66/bios/PCIE_evmc6678_wSoCLib_C66BiosExampleProject.txt&lt;/p&gt; &lt;/blockquote&gt; &lt;p&gt;参考使用：https://e2echina.ti.com/question_answer/dsp_arm/c6000_multicore/f/53/t/10178&lt;/p&gt; &lt;h3 id=&quot;代码说明&quot;&gt;代码说明&lt;/h3&gt; &lt;h4 id=&quot;任务函数初始化&quot;&gt;任务函数初始化&lt;/h4&gt; &lt;p&gt;在main函数中定义任务函数，并启动BIOS。&lt;/p&gt; &lt;pre&gt; &lt;code class=&quot;cpp&quot;&gt; Task_Params params; Task_Params_init (&amp;amp;params); params.stackSize = 36864;...</content>
 </entry>

 

 <entry>
   <title>CUDA并行编程学习（1）-- 现代GPU的体系结构</title>
   <link href="http://localhost:4000/cuda_learning_01"/>
   <id>http://localhost:4000/cuda_learning_01</id>
   <updated>2018-09-19T00:00:00+08:00</updated>
   <content type="html">&lt;hr /&gt;

&lt;p&gt;&lt;img src=&quot;/img/20180919/1.jpg&quot; alt=&quot;avatar&quot; /&gt;&lt;/p&gt;

&lt;center&gt;基于CUDA技术的GPU的体系结构&lt;/center&gt;

&lt;p&gt;上图是一个基于CUDA技术的典型GPU体系结构。这种体系结构由一个高度线程化的多核流处理器(Streaming Multiprocessor，SM)阵列组成。在上图中，两个多流处理器（Streaming Multiprocessor，SM）形成一个构建块，然而，在基于CUDA技术的GPU的每一代之间，每个构建块中SM的数量可能不同。此外，图中的每个SM又包含多个流处理器(Streaming Processor，SP)，它们之间共享控制逻辑和指令缓存。每个GPU都带有若干千兆字节(GB)的 &lt;strong&gt;图形双数据速率&lt;/strong&gt; (Graphics Double Data Rate，GDDR) &lt;strong&gt;DRAM&lt;/strong&gt;，在上图中称为 &lt;strong&gt;全局存储器&lt;/strong&gt;(global memory)。GPU中的这些GDDR DRAM完全不同于CPU体系中安装在主板上的系统DRAM，它们主要是用于图形处理的帧缓冲区存储器。在图形应用程序中，它们用来保存视频图像和用于3D渲染的纹理信息；而对于计算，它们可以作为带宽芯片外存储器。尽管比典型系统存储器的延迟要长，大规模并行应用程序通常通过高带宽来弥补时延。&lt;/p&gt;

&lt;hr /&gt;
</content>
 </entry>

 

 <entry>
   <title>CUDA并行编程学习（0）-- CUDA和GPU</title>
   <link href="http://localhost:4000/cuda_learnning_00"/>
   <id>http://localhost:4000/cuda_learnning_00</id>
   <updated>2018-09-16T00:00:00+08:00</updated>
   <content type="html">&lt;hr /&gt;

&lt;p&gt;GPU能够进行并行计算的原因是因为其内部具有成百上千个计算单元，如果我们能够对程序进行拆分，将整个计算过程拆分成大量的独立子任务，这些大量的计算单元就为并行执行这些任务提供了可能性。&lt;/p&gt;

&lt;p&gt;CUDA使用了单指令多线程（Single Instruction Multiple Threads、SIMT）的并行模式。CUDA GPU包含了大量的基础计算单元，这些单元被称为核，每个核都包含了一个逻辑计算单元（ALU）和一个浮点计算单元（FLU）。多个核集成在一起被称为 &lt;strong&gt;多流处理器&lt;/strong&gt;（Stream Multiprocessor、SM）。&lt;/p&gt;

&lt;p&gt;我们将一个计算任务分解为多个子任务，每个子任务被称为线程，多个线程被组织为线程块。线程块被分解为大小与一个SM中核数量相同的 &lt;strong&gt;线程束&lt;/strong&gt;（warp）。每个线程束由一个特定的SM处理器执行。SM处理器的控制单元指挥其所有核同时在一个线程束的每个线程中执行同一个指令,这称为SIMT。&lt;/p&gt;

&lt;p&gt;在GPU上，芯片的大多数空间被分配给了大量组织成SM处理器的运算大院和共享的控制单元。当一个线程束所需的数据不可获得时，SM处理器会转向执行另一个可获得数据的线程束。GPU关注的是整体的运算吞吐量而不是单个核心的执行速度。&lt;/p&gt;

&lt;hr /&gt;
</content>
 </entry>

 

</feed>