<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

 <title>Suzhengpeng'S Blog</title>
 <link href="http://localhost:4000/atom.xml" rel="self"/>
 <id>http://localhost:4000</id>
 <updated>2018-09-19T23:50:55+08:00</updated>
 <author>
   <name>Su Zhengpeng</name>
   <uri></uri>
   <email>suzhengpeng@hotmail.com</email>
 </author>

 

 <entry>
   <title>CUDA并行编程学习（1）-- 现代GPU的体系结构</title>
   <link href="http://localhost:4000/cuda_learning_01"/>
   <id>http://localhost:4000/cuda_learning_01</id>
   <updated>2018-09-19T00:00:00+08:00</updated>
   <content type="html">&lt;hr /&gt;

&lt;p&gt;&lt;img src=&quot;/img/20180919/1.jpg&quot; alt=&quot;avatar&quot; /&gt;&lt;/p&gt;

&lt;center&gt;基于CUDA技术的GPU的体系结构&lt;/center&gt;

&lt;p&gt;上图是一个基于CUDA技术的典型GPU体系结构。这种体系结构由一个高度线程化的多核流处理器(Streaming Multiprocessor，SM)阵列组成。在上图中，两个多流处理器（Streaming Multiprocessor，SM）形成一个构建块，然而，在基于CUDA技术的GPU的每一代之间，每个构建块中SM的数量可能不同。此外，图中的每个SM又包含多个流处理器(Streaming Processor，SP)，它们之间共享控制逻辑和指令缓存。每个GPU都带有若干千兆字节(GB)的 &lt;strong&gt;图形双数据速率&lt;/strong&gt; (Graphics Double Data Rate，GDDR) &lt;strong&gt;DRAM&lt;/strong&gt;，在上图中称为 &lt;strong&gt;全局存储器&lt;/strong&gt;(global memory)。GPU中的这些GDDR DRAM完全不同于CPU体系中安装在主板上的系统DRAM，它们主要是用于图形处理的帧缓冲区存储器。在图形应用程序中，它们用来保存视频图像和用于3D渲染的纹理信息；而对于计算，它们可以作为带宽芯片外存储器。尽管比典型系统存储器的延迟要长，大规模并行应用程序通常通过高带宽来弥补时延。&lt;/p&gt;

&lt;hr /&gt;
</content>
 </entry>

 

 <entry>
   <title>CUDA并行编程学习（0）-- CUDA和GPU</title>
   <link href="http://localhost:4000/cuda_learnning_00"/>
   <id>http://localhost:4000/cuda_learnning_00</id>
   <updated>2018-09-16T00:00:00+08:00</updated>
   <content type="html">&lt;hr /&gt;

&lt;p&gt;GPU能够进行并行计算的原因是因为其内部具有成百上千个计算单元，如果我们能够对程序进行拆分，将整个计算过程拆分成大量的独立子任务，这些大量的计算单元就为并行执行这些任务提供了可能性。&lt;/p&gt;

&lt;p&gt;CUDA使用了单指令多线程（Single Instruction Multiple Threads、SIMT）的并行模式。CUDA GPU包含了大量的基础计算单元，这些单元被称为核，每个核都包含了一个逻辑计算单元（ALU）和一个浮点计算单元（FLU）。多个核集成在一起被称为 &lt;strong&gt;多流处理器&lt;/strong&gt;（Stream Multiprocessor、SM）。&lt;/p&gt;

&lt;p&gt;我们将一个计算任务分解为多个子任务，每个子任务被称为线程，多个线程被组织为线程块。线程块被分解为大小与一个SM中核数量相同的 &lt;strong&gt;线程束&lt;/strong&gt;（warp）。每个线程束由一个特定的SM处理器执行。SM处理器的控制单元指挥其所有核同时在一个线程束的每个线程中执行同一个指令,这称为SIMT。&lt;/p&gt;

&lt;p&gt;在GPU上，芯片的大多数空间被分配给了大量组织成SM处理器的运算大院和共享的控制单元。当一个线程束所需的数据不可获得时，SM处理器会转向执行另一个可获得数据的线程束。GPU关注的是整体的运算吞吐量而不是单个核心的执行速度。&lt;/p&gt;

&lt;hr /&gt;
</content>
 </entry>

 

 <entry>
   <title>初识 Batch Normalization 算法</title>
   <link href="http://localhost:4000/batch-normalization"/>
   <id>http://localhost:4000/batch-normalization</id>
   <updated>2018-09-11T00:00:00+08:00</updated>
   <content type="html">&lt;hr /&gt; &lt;p&gt;Batch Normalization 算法于2015年在论文《Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift》中发表。主要的作用就是加速网络模型的训练速度。&lt;/p&gt; &lt;h3 id=&quot;bn算法batch-normalization其强大之处如下&quot;&gt;BN算法（Batch Normalization）其强大之处如下&lt;/h3&gt; &lt;p&gt;(1) &lt;strong&gt;你可以选择比较大的初始学习率，让你的训练速度飙涨。&lt;/strong&gt; 以前还需要慢慢调整学习率，甚至在网络训练到一半的时候，还需要想着学习率进一步调小的比例选择多少比较合适，现在我们可以采用初始很大的学习率，然后学习率的衰减速度也很大，因为这个算法收敛很快。当然这个算法即使你选择了较小的学习率，也比以前的收敛速度快，因为它具有快速训练收敛的特性；&lt;/p&gt; &lt;p&gt;(2) &lt;strong&gt;你再也不用去理会过拟合中drop out、L2正则项参数的选择问题。&lt;/strong&gt; 采用BN算法后，你可以移除这两项了参数，或者可以选择更小的L2正则约束参数了，因为BN具有提高网络泛化能力的特性；&lt;/p&gt; &lt;p&gt;(3) &lt;strong&gt;再也不需要使用使用局部响应归一化层了&lt;/strong&gt;（局部响应归一化是Alexnet网络用到的方法，搞视觉的估计比较熟悉），因为BN本身就是一个归一化网络层；&lt;/p&gt; &lt;p&gt;(4)&lt;strong&gt;可以把训练数据彻底打乱&lt;/strong&gt;（防止每批训练的时候，某一个样本都经常被挑选到，文献说这个可以提高1%的精度，这句话我也是百思不得其解啊）。&lt;/p&gt; &lt;h3 id=&quot;什么是internal-covariate-shift-&quot;&gt;什么是Internal Covariate Shift ？&lt;/h3&gt; &lt;p&gt;Covariate Shift 指的是训练集的数据分布和预测集的数据分布不一致，这样的情况下如果我们在训练集上训练出一个分类器，肯定在预测集上不会取得比较好的效果。这种训练集和预测集样本分布不一致的问题就叫做“covariate shift”现象。&lt;/p&gt; &lt;p&gt;假设x是属于特征空间的某一样本点，y是标签。假设q1(x)是测试集中一个样本点的概率密度，q0(x)是训练集中一个样本点的概率密度。最终我们估计一个条件概率密度$p(y|x，θ)$，它由x和一组参数θ=｛θ1，θ2……θm｝所决定。对于一组参数来说，对应loss(θ)函数评估性能的好坏&lt;/p&gt; &lt;p&gt;综上，当我们找出在q0(x)分布上最优的一组θ’时，能否保证q1(x)上测试时也最好呢？&lt;/p&gt; &lt;p&gt;传统机器学习假设训练集和测试集是独立同分布的，即q0(x)=q1(x)，所以可以推出最优θ’依然可以保证q1(x)最优。但现实当中这个假设往往不成立，伴随新数据产生，老数据会过时，当q0(x)不再等于q1(x)时，就被称作covariate shift。&lt;/p&gt; &lt;p&gt;而Internal Covariate Shit 是在网络层级间发生的Convariate Shift。&lt;/p&gt; &lt;h3 id=&quot;输入的归一化处理&quot;&gt;输入的归一化处理&lt;/h3&gt; &lt;p&gt;简单来说BN算法就是在网络的每一层输入的时候，又插入了一个归一化层，也就是先做一个归一化处理，然后再进入网络的下一层。&lt;/p&gt; &lt;hr...</content>
 </entry>

 

 <entry>
   <title>Leetcode 804. Unique Morse Code Words</title>
   <link href="http://localhost:4000/leetcode_804_unique_morse_code_words"/>
   <id>http://localhost:4000/leetcode_804_unique_morse_code_words</id>
   <updated>2018-09-08T00:00:00+08:00</updated>
   <content type="html">&lt;h2 id=&quot;问题描述&quot;&gt;问题描述&lt;/h2&gt; &lt;p&gt;International Morse Code defines a standard encoding where each letter is mapped to a series of dots and dashes, as follows: “a” maps to “.-“, “b” maps to “-…”, “c” maps to “-.-.”, and so on.&lt;/p&gt; &lt;p&gt;For convenience, the full table for the 26 letters of the English...</content>
 </entry>

 

 <entry>
   <title>孪生网络与目标跟踪（2）-- Siamese-FC算法概述</title>
   <link href="http://localhost:4000/siames-network-02"/>
   <id>http://localhost:4000/siames-network-02</id>
   <updated>2018-09-06T00:00:00+08:00</updated>
   <content type="html">&lt;hr /&gt; &lt;p&gt;在《Fully-convolutional siamese networks for object tracking》这篇论文中，作者将孪生网络引入到目标跟踪领域 ，即：提出了Siamese-FC算法。在Siamese-FC出现之前，浅层方法（如：KCF 等）的缺点是不能够充分利用端到端学习（End-to-end Learning）的优点，而使用其他网络（非孪生网络）的缺点则是不能实现跟踪对实时性的要求。&lt;/p&gt; &lt;p&gt;Siamese-FC要求首先离线训练一个深度卷积网络，然后以训练好的深度卷积网络作为函数，在跟踪时实时的计算出跟踪的结果。&lt;/p&gt; &lt;p&gt;算法主页：&lt;a href=&quot;http://www.robots.ox.ac.uk/~luca/siamese-fc.html&quot;&gt;http://www.robots.ox.ac.uk/~luca/siamese-fc.html&lt;/a&gt;&lt;/p&gt; &lt;h3 id=&quot;深度相似性学习&quot;&gt;深度相似性学习&lt;/h3&gt; &lt;p&gt;相似性学习是解决跟踪问题的有效方法之一。Siamese-FC算法中提出，通过深度学习得到一个函数$f(z,x)$，将样本图像z和候选图像x在同样尺寸下进行比较，最终得到相似性评分。x与z相似度越高则评分越高，反之越低。为了在候选图像中寻找目标的位置，Siamese-FC要穷举所有可能的位置，并计算相似性评分。$f(z,x)$则通过带有位置标签的视频数据集训练得到。&lt;/p&gt; &lt;h3 id=&quot;完全卷积孪生框架&quot;&gt;完全卷积孪生框架&lt;/h3&gt; &lt;p&gt;基于深度卷积网络进行相似性学习采用的主要方法是孪生框架。在孪生网络中首先对输入x和z分别使用各自独立的变换ϕ，然后对变换结果使用函数$g$，即整个函数f可以表示为：$f(z,x)=g(ϕ(z), ϕ(x))$ 。&lt;/p&gt; &lt;p&gt;&lt;img src=&quot;/img/20180908/01.png&quot; width=&quot;450&quot; alt=&quot;孪生网络&quot; /&gt;&lt;/p&gt; &lt;center&gt;完全卷积孪生框架&lt;/center&gt; &lt;p&gt;在Siamese-FC算法中提出的卷积框架，对每一个候选图像x进行完全卷积。&lt;/p&gt; &lt;p&gt;&lt;strong&gt;完全卷积的定义：&lt;/strong&gt;&lt;/p&gt; &lt;blockquote&gt; &lt;p&gt;如果一个函数commutes with translation，则称该函数为为完全卷积。&lt;br /&gt; 这里引入$L_τ$标记为变换算子：$(L_τ x)[u] = x[u-τ]$，函数h如果：$h(L_kτ x) = L_τ h(x)$，则称函数h的映射步长为k的完全卷积。&lt;/p&gt; &lt;/blockquote&gt; &lt;p&gt;&lt;strong&gt;完全卷积的优点：&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;使用完全卷积的优点在于，不需要候选图像和样本图像保持相同的大小，这样就可以将一副足够大的图像作为输入送入网络，以此可以在候选图像中划分子窗，并将子窗做变换，将变换结果一次性完成相似度的计算。&lt;/p&gt; &lt;p&gt;&lt;strong&gt;完全卷积的实现：&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;设ϕ为一个卷积嵌入函数（convolutional embedding function），然后将计算得到的特征映射使用一个互相关层联系到一起。即：&lt;/p&gt;...</content>
 </entry>

 

 <entry>
   <title>初识全连接层</title>
   <link href="http://localhost:4000/fully-connected-layer"/>
   <id>http://localhost:4000/fully-connected-layer</id>
   <updated>2018-09-06T00:00:00+08:00</updated>
   <content type="html">&lt;hr /&gt;

&lt;h4 id=&quot;概述&quot;&gt;概述&lt;/h4&gt;

&lt;p&gt;全连接层 Fully Connected Layer 一般位于整个卷积神经网络的最后，负责将卷积输出的二维特征图转化成一维的一个向量，由此实现了端到端的学习过程（即：输入一张图像或一段语音，输出一个向量或信息）。全连接层的每一个结点都与上一层的所有结点相连因而称之为全连接层。由于其全相连的特性，一般全连接层的参数也是最多的。&lt;/p&gt;

&lt;h4 id=&quot;主要作用&quot;&gt;主要作用&lt;/h4&gt;

&lt;p&gt;全连接层的主要作用就是将前层（卷积、池化等层）计算得到的特征空间映射样本标记空间。简单的说就是将特征表示整合成一个值，其优点在于减少特征位置对于分类结果的影响，提高了整个网络的鲁棒性。&lt;/p&gt;

&lt;p&gt;在知乎上有这样一个回答说的很形象。&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;假设你是一只小蚂蚁，你的任务是找小面包。你的视野还比较窄，只能看到很小一片区域。当你找到一片小面包之后，你不知道你找到的是不是全部的小面包，所以你们全部的蚂蚁开了个会，把所有的小面包都拿出来分享了。全连接层就是这个蚂蚁大会~如果提前告诉你全世界就只有一块小面包，你找到之后也就掌握了全部的信息，这种情况下也就没必要引入fc层了&lt;br /&gt;
&lt;strong&gt;作者：田star&lt;/strong&gt;  链接：https://www.zhihu.com/question/41037974/answer/150552142&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;实现方式&quot;&gt;实现方式&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;/img/20180906/01.jpg&quot; width=&quot;450&quot; alt=&quot;孪生网络&quot; /&gt;&lt;/p&gt;
&lt;center&gt;全连接层的计算方式&lt;/center&gt;

&lt;p&gt;如上图所示，一个网络在全连接层之前，生成了5@3×3的特征映射，我们需要只需要使用五个卷积核去和激活函数的输出进行卷积运算，在将五个输出的值相加即可得到一个全连接层的输出值。如果结果是N维的向量，则需要N×5个3×3的卷积核。再加上求和运算对应的权值，参数的数量是非常可观的，由此一般只在网络的之后使用全连接层。&lt;/p&gt;

&lt;p&gt;参考资料：&lt;/p&gt;
&lt;blockquote&gt;
  &lt;ol&gt;
    &lt;li&gt;&lt;strong&gt;CNN 入门讲解：什么是全连接层（Fully Connected Layer）?&lt;/strong&gt; https://zhuanlan.zhihu.com/p/33841176&lt;/li&gt;
    &lt;li&gt;&lt;strong&gt;全连接层的作用是什么？ - 魏秀参 的回答&lt;/strong&gt; https://www.zhihu.com/question/41037974&lt;/li&gt;
    &lt;li&gt;&lt;strong&gt;解释一下全连接层&lt;/strong&gt; https://blog.csdn.net/u011021773/article/details/78121359&lt;/li&gt;
  &lt;/ol&gt;
&lt;/blockquote&gt;

&lt;hr /&gt;
</content>
 </entry>

 

 <entry>
   <title>孪生网络与目标跟踪（1）-- 孪生网络的基本结构</title>
   <link href="http://localhost:4000/siames-network-01"/>
   <id>http://localhost:4000/siames-network-01</id>
   <updated>2018-09-03T00:00:00+08:00</updated>
   <content type="html">&lt;p&gt;Yann LeCun 在他2005年的论文Learning a Similarity Metric Discriminatively, with Application to Face Verificatio中提出使用孪生网络做人脸鉴定。&lt;/p&gt; &lt;h3 id=&quot;核心思想&quot;&gt;核心思想&lt;/h3&gt; &lt;p&gt;这种方法的核心思想在于：通过训练一个网络得到一个函数，这个函数可以将输入映射到目标空间，然后在目标空间中计算输入空间的”语义（semantic）”距离，如使用 $L_1$范数。整个网络的学习过程就是将同一个人的人脸图像的输出最小化，不同的人的人脸图像输出最大化。将原始图像映射进入目标空间的工具就是一个对几何畸变（geometric distortions）具有鲁棒性的卷积网络。更确切的说就是有一系列的函数$G_W(X)$使用W作为参数，我们的目标就是寻找合适的参数W，使得相似矩阵$E_W(X_1,X_2) = ||G_W(X_1) - G_W(X_2) ||$ 在$X_1$和$X_2$属于同一分类（即：人脸图像属于同一个人）时计算得到的结果最大，反之则最小。根据孪生网络的特点，对于输入$X_1$和$X_2$其对应的G和W是相同的。&lt;/p&gt; &lt;h3 id=&quot;设计目标&quot;&gt;设计目标&lt;/h3&gt; &lt;p&gt;设计的可训练系统要在训练时能够同时最小化错误接受率（false accepts）和错误拒绝率（false reject）。同时可将原始图片（raw images）映射到低维空间，以此计算两个输入的相似度距离（即：相似度度量 similarity metric）。&lt;/p&gt; &lt;h3 id=&quot;孪生网络结构&quot;&gt;孪生网络结构&lt;/h3&gt; &lt;p&gt;&lt;img src=&quot;/img/20180904/01.png&quot; width=&quot;450&quot; alt=&quot;孪生网络&quot; /&gt;&lt;/p&gt; &lt;center&gt;孪生网络结构&lt;/center&gt; &lt;h4 id=&quot;整体框架&quot;&gt;整体框架&lt;/h4&gt; &lt;p&gt;$X_1$和$X_2$分别为两个待学习的样本对，Y是样本对的标签（$X_1$ 与 $X_2$ 属于同一个人时 Y为0，反之为1）。$G_W(X_1)$和$G_W(X_2)$为输入的原始图像映射到的低维度空间。而$E_W(X_1,X_2) = ||G_W(X_1) - G_W(X_2)...</content>
 </entry>

 

 <entry>
   <title>孪生网络与目标跟踪（0）-- 孪生网络的基本概念</title>
   <link href="http://localhost:4000/siames-network-00"/>
   <id>http://localhost:4000/siames-network-00</id>
   <updated>2018-09-02T00:00:00+08:00</updated>
   <content type="html">&lt;h3 id=&quot;孪生网络的概念&quot;&gt;孪生网络的概念&lt;/h3&gt; &lt;p&gt;孪生网络即 Siamese Networks ,Siamese 意为“孪生的、连体的”，孪生网络的“孪生”在于两个各自独立的神经网络，具有共同的权值。这种神经网络由Yann Lecun 大神在1993年提出，其论文发表在1994年的NIPS上。孪生网络是用于度量学习的监督网络模型（Supervised models）。&lt;/p&gt; &lt;p&gt;&lt;img src=&quot;/img/20180902/01.jpg&quot; width=&quot;300&quot; alt=&quot;孪生网络&quot; /&gt;&lt;/p&gt; &lt;center&gt;共享权值的孪生神经网络&lt;/center&gt; &lt;h5 id=&quot;共享权值的意义&quot;&gt;共享权值的意义？&lt;/h5&gt; &lt;p&gt;两个神经网络共享权值即意味着两个网络的权值完全相同，这意为这在通过代码实现的时候只需要实现一个即可，而不需要再去实现另一个。&lt;/p&gt; &lt;h5 id=&quot;伪孪生网络&quot;&gt;伪孪生网络&lt;/h5&gt; &lt;p&gt;伪孪生网络即：pseudo-siamese network，存在两个神经独立的神经网络，相比于孪生神经网络他们之间并不共享权值。如下图所示：&lt;/p&gt; &lt;p&gt;&lt;img src=&quot;/img/20180902/02.jpg&quot; width=&quot;300&quot; alt=&quot;孪生网络&quot; /&gt;&lt;/p&gt; &lt;center&gt;伪孪生网络&lt;/center&gt; &lt;p&gt;两边可以是不同的神经网络（如一个是lstm，一个是cnn），也可以是相同类型的神经网络。&lt;/p&gt; &lt;h3 id=&quot;孪生网络的使用&quot;&gt;孪生网络的使用&lt;/h3&gt; &lt;p&gt;一个孪生网络有两个输入，简单来说，孪生网络的直接用途就是衡量这两个输入的差异程度（或者说相似程度）。将两个输入分别Feed 进入两个神经网络，将两个输入映射到新的空间，将输入在新的空间中表示，通过Loss Function来计算两个输入的差异程度（或相似程度）。&lt;/p&gt; &lt;h5 id=&quot;应用场景&quot;&gt;应用场景&lt;/h5&gt; &lt;p&gt;孪生网络适用的场景主要为判断两个输入的相似程度。如：比较两个句子的语义相似程度比较、手写字体的笔迹鉴定、以及目标跟踪领域中的目标（前景）和背景区分。&lt;/p&gt; &lt;h3 id=&quot;loss-function&quot;&gt;Loss Function&lt;/h3&gt; &lt;p&gt;孪生网络的训练目标就是使相似的输入距离尽可能的小，使不同的输入尽可能的大。&lt;/p&gt; &lt;p&gt;孪生网络的两个网络将输入分别转换成向量值，通过计算向量的距离得到输入的差异程度。&lt;/p&gt; &lt;hr /&gt; &lt;p&gt;参考资料：&lt;/p&gt; &lt;blockquote&gt; &lt;ol&gt; &lt;li&gt;&lt;strong&gt;Siamese network...</content>
 </entry>

 

 <entry>
   <title>Leetcode 91. Decode Ways</title>
   <link href="http://localhost:4000/leetcode_91_decode_ways"/>
   <id>http://localhost:4000/leetcode_91_decode_ways</id>
   <updated>2018-09-02T00:00:00+08:00</updated>
   <content type="html">&lt;h2 id=&quot;问题描述&quot;&gt;问题描述&lt;/h2&gt; &lt;p&gt;A message containing letters from A-Z is being encoded to numbers using the following mapping:&lt;/p&gt; &lt;blockquote&gt; &lt;p&gt;‘A’ -&amp;gt; 1&lt;br /&gt; ‘B’ -&amp;gt; 2&lt;br /&gt; …&lt;br /&gt; ‘Z’ -&amp;gt; 26&lt;/p&gt; &lt;/blockquote&gt; &lt;p&gt;Given a non-empty string containing only digits, determine the total number of ways to decode it.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Example 1:&lt;/strong&gt;&lt;/p&gt;...</content>
 </entry>

 

 <entry>
   <title>Opencv3 Mat 结构像素值存储细节</title>
   <link href="http://localhost:4000/opencv-mat-pixel-struct"/>
   <id>http://localhost:4000/opencv-mat-pixel-struct</id>
   <updated>2018-03-02T00:00:00+08:00</updated>
   <content type="html">&lt;p&gt;在Opencv3 中常使用Mat 结构保存图像或数据。&lt;/p&gt; &lt;h3 id=&quot;深度-depth&quot;&gt;深度 Depth&lt;/h3&gt; &lt;p&gt;Mat 结构的深度类型一般有以下6种&lt;/p&gt; &lt;table&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;类型&lt;/th&gt; &lt;th&gt;解释&lt;/th&gt; &lt;th&gt;变量类型&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;CV_8U&lt;/td&gt; &lt;td&gt;单通道8位无符号整数&lt;/td&gt; &lt;td&gt;unsigned char&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;CV_8S&lt;/td&gt; &lt;td&gt;单通道8位有符号整数&lt;/td&gt; &lt;td&gt;char&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;CV_16S&lt;/td&gt; &lt;td&gt;单通道16位有符号整数&lt;/td&gt; &lt;td&gt;short int&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;CV_32S&lt;/td&gt; &lt;td&gt;单通道32位有符号整数&lt;/td&gt; &lt;td&gt;int&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;CV_32F&lt;/td&gt; &lt;td&gt;单通道32位单精度浮点数&lt;/td&gt; &lt;td&gt;float&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;CV_64F&lt;/td&gt; &lt;td&gt;单通道64位双精度浮点数&lt;/td&gt; &lt;td&gt;double&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt;...</content>
 </entry>

 

</feed>